<font size = 4>

### 前序
并发[^ann-concurrency]属于操作系统层面的概念, 所有的编程语言本身是不提供并发机制的(<font color = red>标准库实现, 编译器再调用标准库</font>), 它们全部要依赖运行的平台, 所以像c++, Java, python等所谓的线程本质是对内核相关接口(<font color = red>如Unix环境下POSIX线程库</font>)的封装, swift也不例外!! 

理论上只要对内核的调度机制了解的足够透彻就可以随心所欲的使用线程和进程, 甚至对其进行封装简化, 就像这些语言一样. 如今各大语言中的线程使用已经足够简化, 用户不需要太过了解底层的实现, 但了解这个过程还是很重要的. 笔者将从传统线程编程模式开始逐步引申到现代线程编程模式


### swift中的并发选择
从系统层面来看, 并发只有2种模型:
1. 多进程
2. 多线程

但其实不同内核的线程和进程模型在架构, 实现上是不一样的. 如Linux中站在内核的层面去看, 并没有线程(<font color = red>一种轻量级进程</font>)的这一概念, 但在BSD中进程和线程有明显的区分. 笔者的建议是除非进行系统开发, 否则最好不要使用多进程并发.

> 这里笔者给出一个简单的案例, 只是简单了解一下多进程并发的编程模式


```cpp
#include <unistd.h>
#include <fcntl.h>
#include <sys/stat.h>

#include <algorithm>
#include <initializer_list>

#include <cstdio>
#include <cstdlib>
#include <cstring>

#define _0  0,
#define _1  1,
#define _2  2,
#define _3  3,
#define _4  4,
#define _5  5,
#define _6  6,
#define _7  7,
#define _8  8,
#define _9  9
#define _10  _0 _1 _2 _3 _4 _5 _6 _7 _8 _9


#define _50     _10, _10, _10, _10, _10
#define _100    _50, _50
#define _500    _100, _100, _100, _100, _100

#define range(...) { __VA_ARGS__ }

static auto list = range(_500, _500);

static uint8_t buf[256];

int main() {
    chdir("/tmp");          // 切换工作目录

    unlink("./a.txt");      // 删除文件

    umask(0);               // 创建文件,指定屏蔽字
    auto file = open("./a.txt", O_RDWR | O_CREAT, S_IRUSR | S_IWUSR);
    if(file < 0){
        perror("open");
        exit(-1);
    }

    auto count = 0;

    // 3个子进程
    for(int i = -1; ++i < 3;){
        auto pid = fork();

        // 忽略失败(直接创建下一个子进程), 毕竟这里只是测试
        if(pid < 0){
            perror("fork");
            continue ;
        }

        if(pid == 0){   // 当前位于子进程中

            // 每个子进程循环1000次, 对文件中的内容数字做累加
            //  read --> add --> write
            std::for_each(list.begin(), list.end(), [=](int){
                char buf[128] = {0};

                // 上锁
                lockf(file, F_LOCK, 128);

                auto rlen = pread(file, buf, 128, 0);

                // 读取失败后, 再回去重新读
                //  因为这里读取的是普通文件, 出现错误的概率将很小.
                //  当出现错误时(无论什么错误), 尝试回去重新读取
                if(rlen < 0){
                    lockf(file, F_ULOCK, 128);
                    perror("read");
                    return;
                }

                auto number = 0ll;

                // eof, 第1次
                if(rlen == 0){
                    number = 0;
                }else{
                    number = atoll(buf);
                }

                // add
                number += 1;
                snprintf(buf, 128, "%lld", number);

                // write
                pwrite(file, buf, 128, 0); // ignore error handle

                // 解锁
                lockf(file, F_ULOCK, 128);
            });

            exit(0);
        }
        
        // 有效的子进程数量
        ++count;
    }

    // 等待所有的子进程
    while(true){
        // -1: 等待当前主进程下的任意子进程
        // nullptr, 不关心子进程的收尸状态
        // 0: 选项值(具体看man手册)
        //  当有子进程在运行时, 会阻塞等待它们结束
        //  当没有子进程时(子进程可能已经结束), 会直接返回子进程的进程号(大于0)
        auto wait_pid = waitpid(-1, nullptr, 0);

        wait_pid > 0 ? --count : 0;

        if(count) {
            continue;
        }
        break;
    }


    // 最终在主进程中读取文件的内容, 查看一下累加的值
    if(read(file, ::buf, 256) < 0){
        perror("read");
        return -1;
    }

    printf("%s\n", buf);

    return 0;
}
```

该demo在Mac下使用c++编写, 因为swift不支持fork, demo的功能:
1. 多进程读取文件
2. 将文件中的内容做累加
3. 将累加的结果写入到文件中

整个过程使用文件锁做临界区, 最后的累加结果是3000(<font color = red>从0开始3个子进程每个累加1000次</font>). 这种使用多进程的并发模式会牵扯到很多细节, 笔者建议不要使用这种并发模型. 相应的在应用层面, 可以选择的方式有很多:
1. pthread
2. GCD
3. NSThread
4. NSOperation
5. swift的concurrency

这5种使用方式并不会改变内核中的并发模型, 它们的区别在使用形式上, 说白了就是对内核线程的抽象深度不同, 抽象越高使用越简单, 就越接触不到最底层的细节(<font color = red>为了方便, 笔者称pthread是相对最底层的API</font>). swift中的并发已经将线程抽象成了结构化并发的模型, 其中牵扯到用户态调度的逻辑, 后续会详细学习


### CPU,线程以及调用栈
这三者详细的概念笔者这里不会过多阐述. 线程本质上是内核中的一种数据结构: 用来描述任务的调度状态. 这些状态随着函数的执行过程被不断更改:
1. 时间片
2. 阻塞
3. 自动放弃CPU
4. ...

线程运行过程中会绑定对应的函数调用栈在CPU上执行, 当线程状态发生变化后这3者可能互相脱离绑定:
- 如: 线程阻塞后由内核将其挂起, 但CPU不会空闲, 它可能绑定其他的的线程或进程. 
- 如: 信号的异步调用, CPU和线程很可能没有脱离绑定, 但线程会绑定其他调用栈
- 如: 线程池中线程是复用的, 当线程执行完毕当前的所有函数后, 并不回收给内核, 而是进行睡眠让出CPU, 有新的任务来了后重新绑定调用栈并且又重新绑定其他的CPU

严格来说不能用绑定来描述线程和调用栈的关系, 像第2种情况中当线程被信号打断进入到信号处理函数时, 线程的调用栈其实有2部分:
1. 原调用栈中底部的部分函数
2. 信号处理调用栈


```cpp
#include <unistd.h>
#include <signal.h>
#include <execinfo.h>
#include <pthread/pthread.h>

#include <cstdio>

// 打印函数调用栈
void print_callstack(void){
    void* buf[1024] = {0};
    auto frames = backtrace(buf, 128);
    auto symbols = backtrace_symbols(buf, frames);
    printf("thread<%p>\n", pthread_self());
    for(int i = -1; ++i < frames;){
        printf("%s\n", symbols[i]);
    }
}

// 信号处理
void sig_handle(int){
    print_callstack();
}

int main() {
    // 主线程
    printf("main<%p>\n", pthread_self());

    // 注册信号
    signal(SIGALRM, sig_handle);

    // 5秒后发送
    alarm(5);

    // 主线程阻塞
    while(pause()){
        // 被alarm唤醒(先执行信号函数, 再回来这里执行循环)
        printf("*************************\n");
        print_callstack();
    }

    return 0;
} 

#if 0
main<0x203647840>
thread<0x203647840>                     // 信号唤醒了主线程, 并先进入到信号处理函数
0   cpp                                 0x0000000100003d8c _Z15print_callstackv + 80    // 中间3个已经是新的函数栈桢
1   cpp                                 0x0000000100003e58 _Z10sig_handlei + 20
2   libsystem_platform.dylib            0x000000019e568184 _sigtramp + 56
3   libsystem_c.dylib                   0x000000019e43d480 pause + 44           // 这里还是原来的栈桢
4   cpp                                 0x0000000100003eb8 main + 84
5   dyld                                0x000000019e1b0274 start + 2840
*************************                                                       // 信号处理程序处理完毕后, 循环体打印
thread<0x203647840>                                                             
0   cpp                                 0x0000000100003d8c _Z15print_callstackv + 80 
1   cpp                                 0x0000000100003ed8 main + 116
2   dyld                                0x000000019e1b0274 start + 2840
#endif
```

当前demo中当信号产生后, 进入到信号处理函数是属于异步回调, 这种异步回调是相当于打断了主线程的顺序执行, 被内核强制制造了新的现场. 固使用绑定这个词来描述线程和调用栈之间的关系或许并不贴切, 但为了方便笔者还是以绑定来描述. 同样的原理当使用线程池时, 线程本身是复用的, 但它可以通过绑定调用栈(<font color = red>其实就是回调</font>)从而执行不同的业务. 


### 传统线程模式(1)
先来看一个简单的下载案例(<font color = red>笔者简化了业务</font>)

```cpp
#include <unistd.h>
#include <pthread/pthread.h>
#include <iostream>
#include <sstream>

using namespace std;
static void* sub_thread(void* data){
    cout << "子线程<" << pthread_self() << ">开始下载...\n";        
    sleep(5);       // 模拟下载 __code_3

    cout << "子线程<" << pthread_self() << ">下载成功!\n";
    auto os = ostringstream();
    os.setf(ios::hex);
    os << "hello tierry!";

    return new string(os.str());
}

static void download(std::string url,void(*cbk)(void* _Nullable)){
    pthread_t pid;
    pthread_create(&pid, nullptr,sub_thread, (void*)url.c_str());   // __code_1
    void* ret = nullptr;
    pthread_join(pid, &ret);                                        // __code_2
    if(ret){
        cbk(ret);
    }
}

static void handle(void* data){ //__code_4
    if(data){
        cout << "main<"<< pthread_self() << ">:" << *static_cast<string*>(data) << endl;
        delete static_cast<string*>(data);
    }
}

int main() {
    cout << "main" << "<" << pthread_self() << ">\n";
    download("下载的地址", handle);     // __code_0
    return 0;
}

#if 0
main<0x1fac93840>
子线程<0x16fe87000>开始下载...      // 阻塞5秒
子线程<0x16fe87000>下载成功!        
main<0x1fac93840>:hello tierry!
#endif
```

程序的流程:
1. 主线程发起下载(`__code_0`)
2. 创建下载任务(`__code_1`)
3. 内核调度子线程
4. 子线程内部做下载, 笔者使用睡眠5秒来模拟这个过程(`__code_3`)
5. 子下载完毕后返回数据
6. 主线程在创建子线程后, 采用阻塞等待模式(`__code_2`)
    - 在这个期间主线程不能执行任何操作
7. 子线程返回后, 主线程被唤醒并接收子线程返回的数据(`__code_2`)
8. 主线程调用打印函数(`__code_4`)

整个过程在逻辑上确实是顺序执行的, 但为了顺序执行牺牲主线程: 主线程在子线程请求的5秒内不能做任何事情. 


### 传统线程模式(2)
上一小节的案例可以通过分离线程, 添加异步回调的方式来解决
```cpp
#include <unistd.h>
#include <pthread/pthread.h>

#include <iostream>
#include <queue>
#include <atomic>

using namespace std;

static std::queue<string> main_q;

static atomic_flag flag;

static pthread_t main_tid;

#define $(_code)        \
    do {                \
        while(flag.test_and_set()){ \
            pthread_yield_np(); \
            continue;   \
        }               \
        _code           \
        flag.clear();   \
    }while(false)


static void push(string data){
    $({
        main_q.push(data);
    });

    // 相当于唤醒主线程,
    //  PS: pthread_kill是向指定的线程发信号, 但在Mac中笔者测试的只有
    //  指定主线程时, 这个信号才是成功的
    pthread_kill(main_tid, SIGUSR1);
}

static void pop(){
    while(true){
        string str;
        $({
            if(!main_q.empty()){
                str = main_q.front();
                main_q.pop();
            }else {
                flag.clear();
                return;
            }
        });

        if(!str.empty()){
            cout << "main<" << pthread_self() << ">: " << str << endl;
        }
    }
}

static void* sub_thread(void* data){
    cout << "子线程<" << pthread_self() << ">开始下载...\n";

    sleep(5);       // 模拟下载

    cout << "子线程<" << pthread_self() << ">下载成功!\n";

    push("hello tierry!");  // __code_6

    return nullptr;
}

static void download(std::string url){
    pthread_t pid;
                                        // __code_7
    pthread_create(&pid, nullptr,sub_thread, (void*)url.c_str());

    pthread_detach(pid);                // __code_8
}


int main() {
    main_tid = pthread_self();

    signal(SIGUSR1, SIG_IGN);           // __code_0

    cout << "main" << "<" << pthread_self() << ">\n";

    download("下载的地址");             // __code_1

    sleep(1);
                                        // __code_2
    cout << "main" << "<" << pthread_self() << ">下载期间做其他事情...\n";

    while(pause()){                     // __code_3
        printf("wake up!!\n");          // __code_4
        pop();                          // __code_5
    }
    return 0;
} 

#if 0
子线程<0x16fe87000>开始下载...          //子线程阻塞(5秒) 
main<0x1fac93840>下载期间做其他事情...  // 主线程在子线程阻塞期间可以做其他事情
子线程<0x16fe87000>下载成功!            // 当子线程下载成功后, 会将数据添加到主线程的任务队列, 唤醒主线程
wake up!!                               // 主线程被唤醒
main<0x1fac93840>: hello tierry!        // 执行打印, 后面会继续睡眠, 等待任务
#endif
```

流程:
1. `__code_0`: 主线程注册一个异步信号用来被唤醒
2. `__code_1`: 主线程发起请求
    - 内部创建子线程(`__code_7`)
    - 和子线程分离(`__code_8`)
3. 主线程执行其他任务
    - 睡眠(<font color = red>也是一种任务</font>)
    - 执行一句打印(`__code_2`)
4. 子线程此刻还在进行下载
5. `__code_3`: 主线程挂起, 等待唤醒
6. 当子线程下载完毕后, 将数据添加到主线程的任务队列中, 并唤醒主线程(push函数)
7. 主线程被唤醒, 取出任务打印一下(pop函数)

整个流程并不是顺序执行的, 主线程并不需要一直等待子线程下载完毕, 所以它可以执行其他的任务, 主线程是通过异步通知的方法被唤醒. 实际开发中:
1. 信号唤醒会替换成条件锁
2. 主线程也会关联一个任务队列, 但队列中的元素并不是简单的字符串, 可能是格式统一的回调函数

该模型也算是单一的线程池, 即main线程其实一直被复用. 


### 传统线程模式(3)
使用lambda可以对上一小节的模型做简化, 这样程序看起来更集中

```cpp
int main() {
    main_tid = pthread_self();

    signal(SIGUSR1, SIG_IGN);

    cout << "main" << "<" << pthread_self() << ">\n";

    thread([](void* data){
        cout << "子线程<" << pthread_self() << ">开始下载...\n";

        sleep(5);       // 模拟下载

        cout << "子线程<" << pthread_self() << ">下载成功!\n";

        push("hello tierry!");

        return nullptr;
    }, (void*)"下载的地址").detach();

    sleep(1);

    cout << "main" << "<" << pthread_self() << ">下载期间做其他事情...\n";

    while(pause()){
        printf("wake up!!\n");
        pop();
    }
    return 0;
} 
```

使用c++的线程库可以使用lambda表达式, 这样代码更为集中. thread底层调用的是POSIX线程, 所以本质上是一样的, 流程并不会改变. 现在来总结这3小节案例的缺点:
1. 不管怎么修改, 都不可避免的要使用异步
2. 因为异步的机制, 整个代码在书写形式上并不是顺序化的(<font color = red>结构化</font>)

将异步的处理机制架构成顺序模型是比较困难的, 后面笔者将以iOS(<font color = red>简化</font>)来加以引导.




### 传统线程模式(4)
先看一个简单的案例:
```objc
#include <Foundation/Foundation.h>

typedef CFRunLoopRef EventLoop;
typedef CFRunLoopMode EventMode;

static EventLoop mainloop;

static void req_data(const char* url, void(^cbk)(id _Nullable, NSError* _Nullable)){
    dispatch_async(dispatch_get_global_queue(0, 0), ^{

        auto path = [NSString stringWithCString:url encoding:NSUTF8StringEncoding];

        path = [path stringByAddingPercentEncodingWithAllowedCharacters:NSCharacterSet.URLQueryAllowedCharacterSet];

        NSURLRequest* req = [NSURLRequest requestWithURL:[NSURL URLWithString:path]];

        // 获取到数据
        id e;
        auto data = [NSURLConnection sendSynchronousRequest:req returningResponse:nil error:&e];

        // 解析数据
        id oc = [NSJSONSerialization JSONObjectWithData:data options:0 error:nil];

        // 唤醒主线程
        dispatch_async(dispatch_get_main_queue(), ^{
            e ? cbk(nil, e) : cbk(oc, nil);
        });
    });
}

int main(void){
    mainloop = CFRunLoopGetCurrent();

    constexpr auto url = "http://t.weather.sojson.com/api/weather/city/101030100";

    auto observer = CFRunLoopObserverCreateWithHandler(
        CFAllocatorGetDefault(),kCFRunLoopAllActivities,true,1,
        ^(CFRunLoopObserverRef observer, CFRunLoopActivity activity) {
            if(activity != kCFRunLoopEntry)
                return;

            req_data(url, ^void(NSDictionary* data, NSError* e){
                if(e)
                    return;

                NSDictionary* fir = data[@"data"][@"forecast"][0];
                
                NSLog(@"%@\t\t%@", fir[@"high"], fir[@"low"]);
            });
        });

    CFRunLoopAddObserver(mainloop, observer, kCFRunLoopDefaultMode);

    CFRunLoopRun();

    return 0;
}

#if 0
高温 17℃		低温 8℃
#endif
```

这个案例使用苹果的runloop来模拟UI开发下的基本流程:
1. runloop刚进入时就开始从服务器获取数据
2. 为了演示, 笔者使用了同步请求的接口, 这意味着调用线程将被阻塞, 所以必须开启子线程
3. 子线程请求完数据后, 通过回调的方式向主线程回传数据

这种代码在iOS开发很常见(OC), 它们存在的主要问题: 主线程和子线程传递数据方式不是流程化的, 如果涉及多个异步顺序处理将形成嵌套地狱, 可以自行进行封装达到如下这种效果(<font color = red>并非本例</font>):

```objc
@Async(id, result) = @Await http_req(API.module_home.sysconfig, nil, GET) @Awake
REQ_SUC(){
    [LCSaveData savePaydomain:__res.to_dic.read(@"ossDomain")];
    [LCSaveData saveSysId:__res.to_dic.read(@"sysId")];
    [LCSaveData saveServerId:__res.to_dic.read(@"servId")];
}
@Catch();
@Over(); 

// 笔者封装的OC网络请求, 这里只是举例
```

笔者封装的原理其实很简单:
1. macro
2. 信号量

即在主线程发起请求后, 开辟子线程利用信号量做同步, 然后利用macro抽象顺序的书写语法, 这里不多赘述. 它最主要的优点: 从上往下的书写格式看起来更直观. 这当然算是一种简化使用.  

> swift在语言层面提供了这种语法, 并配合标准库的并发架构实现了结构化并发[^ann-struct-concurrency]. 

### 上下文切换
严格来说上下文切换发生在CPU切换线程时. 当前线程由于某些原因(<font color = red>如时间片, 阻塞IO等</font>)要放弃CPU时, 内核会记录下当前与线程相关的状态信息(<font color = red>寄存器,PC,堆栈指针,TCB等</font>), 并将这些寄存器,PC, FP, TCB等重置为目标运行线程状态. 频繁的上下文切换会带来性能损耗, 所以内核在调度模块其实也做了很多优化, 笔者这里不探究这种层面
> 这里用户态和内核态发生转换时, 也有类似上下文切换机制, 但这种上下文并不是线程的上下文(某些系统实现可能会牵连线程的上下文切换).

从权限层面来看, 用户是无法避免这种切换的. 即使是使用线程池也是一样的. 因为处于线程池中的线程不处于运行状态, 它不占据CPU, 所以当用户唤醒线程池中的线程时, 对应的内核会给该线程分配CPU, 这个时候必然发生上下文的切换. 但它可以避免线程的频繁创建和销毁, 也可以达到一定程度的优化.  笔者指出这一点的目的是为了说明(Mac环境): 
1. gcd框架其实就是线程池机制, 所以也有上下方切换
2. swift协程基于gcd, 所以不能避免上下文切换
3. swift协程是用户层面实现的调度(<font color = red>由swift运行库, swift标准库以及编译器配合实现</font>)
4. swift的结构化并发的效率取决于gcd, 并不是该并发机制的效率
5. 笔者认为swift中的结构化并发只是极简了异步编程模式(<font color = red>其他语言也是一样的原理</font>), 如果单纯的使用传统并发(如OC)效率会更高一点(<font color = red>但程序相对复杂</font>)


### 异步函数
`5.6`新增了一个关键字async, 它用来修饰函数, 这种函数被称为异步函数. 异步函数的特点:
1. 整个函数并不是独立的, 而是可被拆分的
    - 在暂停点被拆分


<br/>

2. 函数的堆栈并非传统意义上的堆栈, 而是异步上下文对象所包含的一部分

<br/>

3. 异步函数内部是多线程执行的(<font color = red>视情况</font>)
    - 如果有暂停点, 则拆分后的函数将在新的线程中执行, 执行完毕后会跳转回暂停点之后

<br/>

4. 异步函数的调用有固定的格式 
    - 阻塞调用: 使用`await`
    - 分离调用: 使用: 1. `await let`; 2. Task

> 关于异步函数怎么拆分的, 这个将在后面的小节详细探究


### 定义异步函数
```swift
func ThreadInfo(other: String = #function) {
    print("\(other + ":")thread<\(pthread_main_np() == 1 ? "main": "sub"),\(pthread_self())>")
}

func f() async {
    ThreadInfo(other: #function)
} 
```

`f`通过`aysnc`修饰, 它是一个异步函数, 一般情况下异步函数在子线程中执行:

```swift
// 打印一下主线程
ThreadInfo(other:"main") 

// 分离调用异步函数
await f()

#if false 
main():thread<main,0x00000001ec77f840>
f():thread<sub,0x000000016fe87000>
#endif
```
可以发现主线程中以await形式调用异步函数时, 异步函数在子线程中执行. 这里并不能确定主线程是否真被阻塞. 看下面的案例

```swift
func f() async {
    ThreadInfo(other: #function)
    sleep(1)
}
await f()
ThreadInfo(other: "main()") 

#if false
f():thread<sub,0x000000016fe87000>          // 程序运行后,立即打印, 然后会睡眠1秒
main():thread<main,0x00000001ec77f840>      // 1秒后打印, 说明主线程被阻塞了
#endif
```

如果以所谓的分离方式调用, 则f函数一定在子线程中执行, 但main始终会等待子线程执行完毕

```swift
func f() async {
    ThreadInfo(other: #function)
    sleep(1)
    DispatchQueue.main.async {
        ThreadInfo(other: "main():\(#line)")// __code_12
        print("wake main runloop")
    }
}
// 分离方式调用, 这时的await可以省略(不阻塞主线程)
async let result = await f()  
ThreadInfo(other: "main():\(#line)")        // __code_18

#if false 
main():18:thread<main,0x00000001ec77f840>   // __code_18
f():thread<sub,0x000000016fe87000>          // f异步函数的打印(子线程中). 这里不能确定是先执行main的打印还是f的打印, 因为调度时机是不确定的
main():12:thread<main,0x00000001ec77f840>   // 1秒后在子线程中唤醒主线程(__code_12)
wake main runloop                           // 测试打印
Program ended with exit code: 0             // 整个进程结束
#endif
```

通过这个测试有这几个结论:
1. 主线程会等待异步函数执行完毕后才结束, 整个进程也就结束
2. 异步函数内的机制是gcd, 因为异步函数在结束前通过gcd的主队列唤醒主线程, 并且主线程真的被唤醒了
3. 通过第2条的结论, 可以推断:
    - 主线程运行在`gcd_main_q`上
    - 主线程在执行完`__code_18`后一定启动了runloop(<font color = red>这个将会在后续进行汇编的验证</font>)


### 不一定开辟线程1
main函数是一个特例, 在main函数上进行的异步函数调用一定会开辟新的的线程. 但在异步函数中调用其他异步函数时, 并不确定是否开启子线程, 先来看分离时的情况:

```swift
func f2() async {
    ThreadInfo(other: "f2()")
}

func f() async {
    for _ in 1...10 {
        print("----------------------------")
        ThreadInfo(other: "f1()")
        async let res = f2()            // __code_detatch
    }
}


ThreadInfo(other: "main():\(#line)")
async let _ = f()


#if false
main():36:thread<main,0x00000001ec77f840>
----------------------------
f1():thread<sub,0x000000016fe87000>
f2():thread<sub,0x000000016fe87000>
----------------------------
f1():thread<sub,0x000000016fe87000>
f2():thread<sub,0x000000016fe87000>
----------------------------
f1():thread<sub,0x000000016ff13000>
f2():thread<sub,0x000000016ff13000>
----------------------------
f1():thread<sub,0x000000016ff13000>
f2():thread<sub,0x000000016ff13000>
----------------------------
f1():thread<sub,0x000000016ff13000>
f2():thread<sub,0x000000016ff13000>
----------------------------
f1():thread<sub,0x000000016ff13000>
f2():thread<sub,0x000000016ff13000>
----------------------------
f1():thread<sub,0x000000016ff13000>
f2():thread<sub,0x000000016ff13000>
----------------------------
f1():thread<sub,0x000000016ff13000>
f2():thread<sub,0x000000016ff13000>
----------------------------
f1():thread<sub,0x000000016ff13000>
f2():thread<sub,0x000000016ff13000>
----------------------------
f1():thread<sub,0x000000016ff13000>
f2():thread<sub,0x000000016ff13000>
#endif
```

<font color = red>这个测试结果并不能作为推导一些结论所需要的样本数据</font>, 也就是说f1要不要开辟线程去执行f2是不确定的. 但有一个隐式的结论: <font color = red>即使是分离调用, 每次循环结束后f1也会等待f2</font>. 
> 至于这些原因都会在后面的源码分析中说明

再来看一下f1阻塞调用f2时, 测试情况

```swift
func f2() async {
    ThreadInfo(other: "f2()")
}

func f() async {
    for _ in 1...10 {
        print("----------------------------")
        ThreadInfo(other: "f1()")
        await f2()
    }
}


ThreadInfo(other: "main():\(#line)")
async let _ = f() 

#if false
main():42:thread<main,0x00000001ec77f840>
----------------------------
f1():thread<sub,0x000000016fe87000>
f2():thread<sub,0x000000016fe87000>
----------------------------
f1():thread<sub,0x000000016fe87000>
f2():thread<sub,0x000000016fe87000>
----------------------------
f1():thread<sub,0x000000016fe87000>
f2():thread<sub,0x000000016fe87000>
----------------------------
f1():thread<sub,0x000000016fe87000>
f2():thread<sub,0x000000016fe87000>
----------------------------
f1():thread<sub,0x000000016fe87000>
f2():thread<sub,0x000000016fe87000>
----------------------------
f1():thread<sub,0x000000016fe87000>
f2():thread<sub,0x000000016fe87000>
----------------------------
f1():thread<sub,0x000000016fe87000>
f2():thread<sub,0x000000016fe87000>
----------------------------
f1():thread<sub,0x000000016fe87000>
f2():thread<sub,0x000000016fe87000>
----------------------------
f1():thread<sub,0x000000016fe87000>
f2():thread<sub,0x000000016fe87000>
----------------------------
f1():thread<sub,0x000000016fe87000>
f2():thread<sub,0x000000016fe87000>
#endif
```

这个笔者直接说结论: <font color = red>f1不会开辟线程去执行f2</font>(后面有汇编和源码说明)

### 死锁??
使用swift并发机制时, 要注意死锁的问题, 先来看一下案例

```swift
func ThreadInfo(other: String = #function) {
    print("\(other + ":")thread<\(pthread_main_np() == 1 ? "main": "sub"),\(pthread_self())>")
}

var lock = os.OSAllocatedUnfairLock()

func f() async {
    lock.lock()                         
    ThreadInfo(other: "f1()-locked")        
    try! await Task.sleep(nanoseconds: UInt64(1e9))
    ThreadInfo(other: "f1()-unlock")        // 解锁时可能不在加锁的线程, 所以这里可能直接闪退
    lock.unlock()
}


ThreadInfo(other: "main():\(#line)")
await f() 
```

测试中使用了操作系统的锁, 如果在线程1中上锁, 但在线程2中解锁将直接异常结束程序, 由于swift中异步函数在暂停前后可能会切换线程, 所以该测试程序可能直接异常结束


### 思考
根据前面的简单测试, 现在最关心的问题:
1. 什么是所谓的拆分函数
2. 暂停点是什么, 为什么暂停点前后所在的线程可能不一样? 如果涉及到函数参数, 局部对象会有什么问题?
3. swift怎么做到用户态切换线程的


### 异步main函数
swift中用户在所谓的`main.swift`中书写的代码其实并不是真正的程序入口, 它是由swift动态库调用的, 特别是程序中如果出现了异步函数的调用, 则main函数本身会被编译器编译成异步函数, 所以真正进入到用户代码前实际上做了很多工作. 看下面的测试案例

```swift
func test() async {
    print("hello")
}

await test() 
```

整个代码书写在`main.swift`中, 但它只是用户代码的入口, 在程序启动后, 要经过很多步骤才会来到这里. 首先通过lldb做一下测试, 发现start函数启动后, 确实进入了main函数, 但该main函数并不是用户书写的代码, 而是在为准备进入用户书写的main做初始化
```lua
swift`main:
    0x10000396c <+0>:   sub    sp, sp, #0x20
    0x100003970 <+4>:   stp    x29, x30, [sp, #0x10]
    0x100003974 <+8>:   add    x29, sp, #0x10
    0x100003978 <+12>:  adrp   x8, 1
    0x10000397c <+16>:  add    x8, x8, #0x90
    0x100003980 <+20>:  add    x0, x8, #0x10
    0x100003984 <+24>:  mov    w8, #0x18                ; =24 
    0x100003988 <+28>:  mov    x1, x8
    0x10000398c <+32>:  mov    w8, #0x7                 ; =7 
    0x100003990 <+36>:  mov    x2, x8
->  0x100003994 <+40>:  bl     0x100003ee8              ; symbol stub for: swift_allocObject
                                                        ; heap
    0x100003998 <+44>:  mov    x4, x0                   ; x4 = heap
    0x10000399c <+48>:  adrp   x8, 5                   
    0x1000039a0 <+52>:  add    x8, x8, #0x0             ; async_MainTu
    0x1000039a4 <+56>:  str    x8, [x4, #0x10]          ; *(x4 + 0x10(16)) = heap 
    0x1000039a8 <+60>:  mov    w8, #0x800               ; =2048 
    0x1000039ac <+64>:  mov    x0, x8
    0x1000039b0 <+68>:  mov    x1, #0x0                 ; =0 
    0x1000039b4 <+72>:  adrp   x8, 1
    0x1000039b8 <+76>:  ldr    x8, [x8, #0x30]
    0x1000039bc <+80>:  add    x2, x8, #0x8
    0x1000039c0 <+84>:  adrp   x3, 5
    0x1000039c4 <+88>:  add    x3, x3, #0x10            ; async function pointer to partial apply forwarder for reabstraction thunk helper from @escaping @convention(thin) @async () -> () to @escaping @callee_guaranteed @async () -> (@out (), @error @owned Swift.Error)
    0x1000039c8 <+92>:  bl     0x100003f30              ; symbol stub for: swift_task_create
                                                        ;   一个很重要的函数, 参数
                                                        ;   x0: 2048, 表示异步任务的选项
                                                        ;   x1: 0     一个指针, 这里传递的是空
                                                        ;   x2: ()    表示返回值的metadata
                                                        ;   x3: 0x100008010  异步函数的入口
                                                        ;   x4: heap  异步函数需要的上下文
                                                        ; 实际内部创建了一个 {AsyncTask*, AsyncContext}, 返回值放在x0, x1
                                                        
    0x1000039cc <+96>:  str    x0, [sp]
    0x1000039d0 <+100>: bl     0x100003f48              ; symbol stub for: swift_task_getMainExecutor
                                                        ;   获取串行执行器 {Identity(gcd_main_q), Implementation(串行执行器的实现者)}
    0x1000039d4 <+104>: mov    x2, x0
    0x1000039d8 <+108>: ldr    x0, [sp]
    0x1000039dc <+112>: str    x2, [sp, #0x8]
    0x1000039e0 <+116>: mov    x2, x1
    0x1000039e4 <+120>: ldr    x1, [sp, #0x8]
    0x1000039e8 <+124>: bl     0x100003f0c              ; symbol stub for: swift_job_run
                                                        ;   这一步内部会找到 0x10008010这个地址, 并开始进入到异步main函数

    0x1000039ec <+128>: bl     0x100003f24              ; symbol stub for: swift_task_asyncMainDrainQueue
                                                        ; 在主线程启动runloop, 后续通过主队列唤醒主线程
    0x1000039f0 <+132>: brk    #0x1 
```

这个汇编简单展示了程序的启动过程, 但还有很多细节, 下面通过源码来探究一下最终是怎么进入到用户书写的代码中

```cpp
SWIFT_CC(swift)
AsyncTaskAndContext swift::swift_task_create(
    size_t rawTaskCreateFlags,
    TaskOptionRecord *options,
    const Metadata *futureResultType,
    void *closureEntry, HeapObject *closureContext) {
    // 参数是2048, 即2的11次方, 第11bit位为1, 0b100000000000
    // 对应的选项是 Task_InheritContext
  TaskCreateFlags taskCreateFlags(rawTaskCreateFlags);

// false
  if (taskCreateFlags.isDiscardingTask()) {
      // 如果task的结果是被丢弃的, 则taskEntry ==> void(AsyncContext*) * ==> void(*)(AsyncContext*)
    ThinNullaryAsyncSignature::FunctionType *taskEntry;
    size_t initialContextSize; // 异步上下文大小

      // closureEntry由swift创建, 它的类型是 AsyncFunctionPointer<AsyncSignature<void(), false>>*
      // 将 closureEntry 还原, 取出函数的入口和函数的上下文大小
      // 通过编译器的调试, 该地址要经过解密后才能还原出正确的类型
    std::tie(taskEntry, initialContextSize) =
      getAsyncClosureEntryPointAndContextSize<
        ThinNullaryAsyncSignature,
        SpecialPointerAuthDiscriminators::AsyncThinNullaryFunction>(closureEntry); //0x00000020ffffbbe8

      // swift_task_create_common最终会调用到swift_task_create_commonImpl
      //    这个由汇编调试出来
    return swift_task_create_common(
        rawTaskCreateFlags, options, futureResultType,
        reinterpret_cast<TaskContinuationFunction *>(taskEntry), closureContext,
        initialContextSize);

// true, 这里还原入口地址(说明编译器创建的地址是变体指针)为真实的类型, 该对象中存储了入口地址
  } else {
      // task的结果是未丢弃的, 则taskEntry ==> void(*)(void*)
    FutureAsyncSignature::FunctionType *taskEntry;
    size_t initialContextSize;

    std::tie(taskEntry, initialContextSize) =
        getAsyncClosureEntryPointAndContextSize<
            FutureAsyncSignature,
            SpecialPointerAuthDiscriminators::AsyncFutureFunction>(closureEntry);

    return swift_task_create_common(
        rawTaskCreateFlags, options, futureResultType,
        reinterpret_cast<TaskContinuationFunction *>(taskEntry), closureContext,
        initialContextSize);
  }
} 



swift_task_create_commonImpl(size_t rawTaskCreateFlags,
                             TaskOptionRecord *options,
                             const Metadata *futureResultTypeMetadata,
                             TaskContinuationFunction *function, /*void(AsyncContext*)*/
                             void *closureContext, size_t initialContextSize) {

    // 复制task标记
  TaskCreateFlags taskCreateFlags(rawTaskCreateFlags);

    // 作业标记(Job)
    //  初始化: Kind = 0(Task)
    //         Priority = 0(UN),
    //         剩余bit是0
    //  后面是根据情况会修改相关的bit位
  JobFlags jobFlags(JobKind::Task, JobPriority::Unspecified);

  // Propagate task-creation flags to job flags as appropriate.
    // 如果外界的语义造成了要创建子task(编译器识别后做的标记), 这里就直接标记job
  jobFlags.task_setIsChildTask(taskCreateFlags.isChildTask());

    // 返回值的类型
  ResultTypeInfo futureResultType;
  #if !SWIFT_CONCURRENCY_EMBEDDED
  futureResultType.metadata = futureResultTypeMetadata;
  #endif

  // Collect the options we know about.
  SerialExecutorRef serialExecutor = SerialExecutorRef::generic();
  TaskExecutorRef taskExecutor = TaskExecutorRef::undefined();
  bool taskExecutorIsOwned = false;
  TaskGroup *group = nullptr;
  AsyncLet *asyncLet = nullptr;
  bool hasAsyncLetResultBuffer = false;
  RunInlineTaskOptionRecord *runInlineOption = nullptr;
  for (auto option = options; option; option = option->getParent()) {
    switch (option->getKind()) {
           // 串行执行器
    case TaskOptionRecordKind::InitialSerialExecutor:
      serialExecutor = cast<InitialSerialExecutorTaskOptionRecord>(option)
                          ->getExecutorRef();
      break;

    case TaskOptionRecordKind::InitialTaskExecutorUnowned:
      taskExecutor = cast<InitialTaskExecutorRefPreferenceTaskOptionRecord>(option)
                         ->getExecutorRef();
      jobFlags.task_setHasInitialTaskExecutorPreference(true);
      taskExecutorIsOwned = false;
      break;

    case TaskOptionRecordKind::InitialTaskExecutorOwned:
      #if SWIFT_CONCURRENCY_EMBEDDED
      swift_unreachable("owned TaskExecutor cannot be used in embedded Swift");
      #else
      taskExecutor = cast<InitialTaskExecutorOwnedPreferenceTaskOptionRecord>(option)
                         ->getExecutorRefFromUnownedTaskExecutor();
      taskExecutorIsOwned = true;
      jobFlags.task_setHasInitialTaskExecutorPreference(true);
      #endif
      break;

    case TaskOptionRecordKind::TaskGroup:
      group = cast<TaskGroupTaskOptionRecord>(option)->getGroup();
      assert(group && "Missing group");
      jobFlags.task_setIsGroupChildTask(true);
      break;

    case TaskOptionRecordKind::AsyncLet:
      asyncLet = cast<AsyncLetTaskOptionRecord>(option)->getAsyncLet();
      assert(asyncLet && "Missing async let storage");
      jobFlags.task_setIsAsyncLetTask(true);
      jobFlags.task_setIsChildTask(true);
      break;

    case TaskOptionRecordKind::AsyncLetWithBuffer: {
      auto *aletRecord = cast<AsyncLetWithBufferTaskOptionRecord>(option);
      asyncLet = aletRecord->getAsyncLet();
      // TODO: Actually digest the result buffer into the async let task
      // context, so that we can emplace the eventual result there instead
      // of in a FutureFragment.
      hasAsyncLetResultBuffer = true;
      assert(asyncLet && "Missing async let storage");

      jobFlags.task_setIsAsyncLetTask(true);
      jobFlags.task_setIsChildTask(true);
      break;
    }
    case TaskOptionRecordKind::RunInline: {
      runInlineOption = cast<RunInlineTaskOptionRecord>(option);
      // TODO (rokhinip): We seem to be creating runInline tasks like detached
      // tasks but they need to maintain the voucher and priority of calling
      // thread and therefore need to behave a bit more like SC child tasks.
      break;
    }
    case TaskOptionRecordKind::ResultTypeInfo: {
#if SWIFT_CONCURRENCY_EMBEDDED
      auto *typeInfo = cast<ResultTypeInfoTaskOptionRecord>(option);
      futureResultType = {
          .size = typeInfo->size,
          .alignMask = typeInfo->alignMask,
          .initializeWithCopy = typeInfo->initializeWithCopy,
          .storeEnumTagSinglePayload = typeInfo->storeEnumTagSinglePayload,
          .destroy = typeInfo->destroy,
      };
      break;
#else
      swift_unreachable("ResultTypeInfo in non-embedded");
#endif
    }
    }
  }

  #if SWIFT_CONCURRENCY_EMBEDDED
  assert(!futureResultType.isNull());
  #endif

    // 标记job的返回值
  if (!futureResultType.isNull()) {
    jobFlags.task_setIsFuture(true);
    assert(initialContextSize >= sizeof(FutureAsyncContext));
  }

  AsyncTask *currentTask = swift_task_getCurrent();
    // 有3种情况jobFlags的isChildTask置位
    //  > taskCreateFlags.isChildTask == true
    //  > parent中有类型是AsyncLet
    //  > parent中有类型是AsyncLetWithBuffer
  AsyncTask *parent = jobFlags.task_isChildTask() ? currentTask : nullptr;

  if (group) {
    assert(parent && "a task created in a group must be a child task");
    // Add to the task group, if requested.
    if (taskCreateFlags.addPendingGroupTaskUnconditionally()) {
      assert(group && "Missing group");
      swift_taskGroup_addPending(group, /*unconditionally=*/true);
    }
  }

  // Start with user specified priority at creation time (if any)
    // 根据taskCreateFlags以及jobFlags的不同指定不同的Job优先级
  JobPriority basePriority = (taskCreateFlags.getRequestedPriority());

  if (taskCreateFlags.isInlineTask()) {
      // 如果当前想要创建inline-task, 取当前线程的优先级(Mac平台则会使用Dispatch.Oos)
     SWIFT_TASK_DEBUG_LOG("Creating an inline task from %p", currentTask);

     // We'll take the current priority and set it as base and escalated
     // priority of the task. No UI->IN downgrade needed.
     basePriority = swift_task_getCurrentThreadPriority();

  } else if (taskIsDetached(taskCreateFlags, jobFlags)) {
      //    job.not_contain(task_isAsyncLetTask) &&
      //    job.not_contain(task_isGroupChildTask) &&
      //    task.not_contain(copyTaskLocals) &&
      //    task.not_contain(isInlineTask)
     SWIFT_TASK_DEBUG_LOG("Creating a detached task from %p", currentTask);
     // Case 1: No priority specified
     //    Base priority = UN
     //    Escalated priority = UN
     // Case 2: Priority specified
     //    Base priority = user specified priority
     //    Escalated priority = UN
     //
     // Task will be created with max priority = max(base priority, UN) = base
     // priority. We shouldn't need to do any additional manipulations here since
     // basePriority should already be the right value
      // 不需要做额外的操作, 因为此时basePriority应该已经是正常值


  } else if (taskIsUnstructured(taskCreateFlags, jobFlags)) { // 非结构化
      //    job.not_contain(task_isAsyncLetTask) &&
      //    job.not_contain(task_isGroupChildTask) &&
      //    task.not_contain(isInlineTask)
     SWIFT_TASK_DEBUG_LOG("Creating an unstructured task from %p", currentTask);

    if (isUnspecified(basePriority)) {
      // Case 1: No priority specified
      //    Base priority = Base priority of parent with a UI -> IN downgrade
      //    Escalated priority = UN
      if (currentTask) { // 继承当前task的优先级
        basePriority = currentTask->_private().BasePriority;
      } else {          // 继承当前线程的优先级
        basePriority = swift_task_getCurrentThreadPriority();
      }
        // 最高为UI
      basePriority = withUserInteractivePriorityDowngrade(basePriority);
    } else {
      // Case 2: User specified a priority
      //    Base priority = user specified priority
      //    Escalated priority = UN
    }

    // Task will be created with max priority = max(base priority, UN) = base
    // priority
  } else { // 结构化的task
    // Is a structured concurrency child task. Must have a parent.
    assert((asyncLet || group) && parent);
    SWIFT_TASK_DEBUG_LOG("Creating an structured concurrency task from %p", currentTask);

    if (isUnspecified(basePriority)) {
      // Case 1: No priority specified
      //    Base priority = Base priority of parent with a UI -> IN downgrade
      //    Escalated priority = Escalated priority of parent with a UI -> IN
      //    downgrade
      JobPriority parentBasePri = parent->_private().BasePriority;
      basePriority = withUserInteractivePriorityDowngrade(parentBasePri);
    } else {
      // Case 2: User priority specified
      //    Base priority = User specified priority
      //    Escalated priority = Escalated priority of parent with a UI -> IN
      //    downgrade
    }

    // Task will be created with escalated priority = base priority. We will
    // update the escalated priority with the right rules in
    // updateNewChildWithParentAndGroupState when we link the child into
    // the parent task/task group since we'll have the right
    // synchronization then.
  }

  if (isUnspecified(basePriority)) {
     basePriority = JobPriority::Default;
  }// 优先级判断完毕

  SWIFT_TASK_DEBUG_LOG("Task's base priority = %#zx", basePriority);

    // 计算大小
    //  实际空间在逻辑上分为这几部分(0开始加):
    //  1. += AsyncTask
    //  2. += ChildFragment
    //  3. += GroupChildFragment
    //  4. += 如果需要接收返回值 ? (fragmentSize + FutureAsyncContextPrefix) : AsyncContextPrefix
    //  5. 对齐到16的倍数, 此刻是headerSize
    //  6. += initialContextSize (amountToAllocate, 16倍数)
  size_t headerSize, amountToAllocate;
  std::tie(headerSize, amountToAllocate) = amountToAllocateForHeaderAndTask(
      parent, group, futureResultType, initialContextSize);

  unsigned initialSlabSize = 512;

  void *allocation = nullptr;
  if (asyncLet) {
    assert(parent);

    // If there isn't enough room in the fixed async let allocation to
    // set up the initial context, then we'll have to allocate more space
    // from the parent.
    if (asyncLet->getSizeOfPreallocatedSpace() < amountToAllocate) {
      hasAsyncLetResultBuffer = false;
    }

    // DEPRECATED. This is separated from the above condition because we
    // also have to handle an older async let ABI that did not provide
    // space for the initial slab in the compiler-generated preallocation.
    if (!hasAsyncLetResultBuffer) {
        // 返回到外界的指针类型是void*, 但实际返回的是 Allocation*,
        // 但偏移了16字节
      allocation = _swift_task_alloc_specific(parent,
                                          amountToAllocate + initialSlabSize);
    } else {
        // 真实的指针:AsyncLet(640字节)*, 但对于AsyncLet*的实现中头部有80字节(AsyncLetImpl*),
        //  返回到这里的指针(allocation)偏移了sizeof(AsyncLetImpl)(80字节),
        //  这个对于外界来说实际是数据开始的地址
      allocation = asyncLet->getPreallocatedSpace();
      assert(asyncLet->getSizeOfPreallocatedSpace() >= amountToAllocate
             && "async let does not preallocate enough space for child task");

        // 560字节 - amountToAllocate 必须 >= 0
      initialSlabSize = asyncLet->getSizeOfPreallocatedSpace()
                          - amountToAllocate;
    }
  } else if (runInlineOption && runInlineOption->getAllocation()) {
    // NOTE: If the space required for the task and initial context was
    //       greater than SWIFT_TASK_RUN_INLINE_INITIAL_CONTEXT_BYTES,
    //       getAllocation will return nullptr and we'll fall back to malloc to
    //       allocate the buffer.
    //
    // This was already checked in swift_task_run_inline.
    size_t runInlineBufferBytes = runInlineOption->getAllocationBytes();
    assert(amountToAllocate <= runInlineBufferBytes);
    allocation = runInlineOption->getAllocation();
    initialSlabSize = runInlineBufferBytes - amountToAllocate;
  } else {
    allocation = malloc(amountToAllocate);
  }
  SWIFT_TASK_DEBUG_LOG("allocate task %p, parent = %p, slab %u", allocation,
                       parent, initialSlabSize);

  AsyncContext *initialContext =
    reinterpret_cast<AsyncContext*>(
      reinterpret_cast<char*>(allocation) + headerSize);

  //  We can't just use `function` because it uses the new async function entry
  //  ABI -- passing parameters, closure context, indirect result addresses
  //  directly -- but AsyncTask->ResumeTask expects the signature to be
  //  `void (*, *, swiftasync *)`.
  //  Instead we use an adapter. This adaptor should use the storage prefixed to
  //  the async context to get at the parameters.
  //  See e.g. FutureAsyncContextPrefix.
    // 我们不能只使用 `function`，因为它使用新的异步函数入口ABI——直接传递参数、闭包上下文、间接结果地址——但 AsyncTask->ResumeTask 期望签名为 `void (*, *, swiftasync *)`。
    // 相反，我们使用适配器。此适配器应使用以异步上下文为前缀的存储来获取参数。
    // 例如，参见 FutureAsyncContextPrefix。

  if (futureResultType.isNull() || taskCreateFlags.isDiscardingTask()) {
    auto asyncContextPrefix = reinterpret_cast<AsyncContextPrefix *>(
        reinterpret_cast<char *>(allocation) + headerSize -
        sizeof(AsyncContextPrefix));
    asyncContextPrefix->asyncEntryPoint =
        reinterpret_cast<AsyncVoidClosureEntryPoint *>(function);
    asyncContextPrefix->closureContext = closureContext;
    function = non_future_adapter;
    assert(sizeof(AsyncContextPrefix) == 3 * sizeof(void *));
  } else {
    auto asyncContextPrefix = reinterpret_cast<FutureAsyncContextPrefix *>(
        reinterpret_cast<char *>(allocation) + headerSize -
        sizeof(FutureAsyncContextPrefix));
    asyncContextPrefix->asyncEntryPoint =
        reinterpret_cast<AsyncGenericClosureEntryPoint *>(function);
    function = future_adapter;
    asyncContextPrefix->closureContext = closureContext;
    assert(sizeof(FutureAsyncContextPrefix) == 4 * sizeof(void *));
  }

  // Only attempt to inherit parent's executor preference if we didn't set one
  // explicitly, which we've recorded in the flag by noticing a task create
  // option higher up in this func.
  if (!jobFlags.task_hasInitialTaskExecutorPreference()) {
    // do we have a parent we can inherit the task executor from?
    if (parent) {
      auto parentTaskExecutor = parent->getPreferredTaskExecutor();
      if (parentTaskExecutor.isDefined()) {
        jobFlags.task_setHasInitialTaskExecutorPreference(true);
        taskExecutor = parentTaskExecutor;
      }
    }
  }

  // Initialize the task so that resuming it will run the given
  // function on the initial context.
  AsyncTask *task = nullptr;
    // 不是分离的任务需要凭证(要等待)
  bool captureCurrentVoucher = !taskIsDetached(taskCreateFlags, jobFlags);
  if (asyncLet) {
    // Initialize the refcount bits to "immortal", so that
    // ARC operations don't have any effect on the task.
    task = new (allocation)
        AsyncTask(taskHeapMetadataPtr, InlineRefCounts::Immortal, jobFlags,
                  function, initialContext, captureCurrentVoucher);
  } else {
    task = new (allocation) AsyncTask(taskHeapMetadataPtr, jobFlags, function,
                                      initialContext, captureCurrentVoucher);
  }

  // Initialize the child fragment if applicable.
  if (parent) {
    auto childFragment = task->childFragment();
    ::new (childFragment) AsyncTask::ChildFragment(parent);
  }

  // Initialize the group child fragment if applicable.
  if (group) {
    auto groupChildFragment = task->groupChildFragment();
    ::new (groupChildFragment) AsyncTask::GroupChildFragment(group);
  }

  // Initialize the future fragment if applicable.
  if (!futureResultType.isNull()) {
    assert(task->isFuture());
    auto futureFragment = task->futureFragment();
    ::new (futureFragment) FutureFragment(futureResultType);

    // Set up the context for the future so there is no error, and a successful
    // result will be written into the future fragment's storage.
    auto futureAsyncContextPrefix =
        reinterpret_cast<FutureAsyncContextPrefix *>(
            reinterpret_cast<char *>(allocation) + headerSize -
            sizeof(FutureAsyncContextPrefix));
    futureAsyncContextPrefix->indirectResult = futureFragment->getStoragePtr();
  }
#if 0
    AsyncTask的过程:
        1. 根据编译器提供参数
        2. 确定parent(有AsyncLet或AsyncLetWithBuffer或外界直接指定childTask)
        3. 确定group
        4. 确定futureResultType
        5. 确定优先级
        6. 分配内存(计算大小)
        7. 构造AsyncTask
        8. 初始化AsyncTask的空间
        9. 初始化其他相关部分
    AsyncTask空间的内容(headerSize部分)
        1. AsyncTask: 使用构造方法初始化
            taskHeapMetadataPtr(Job.metadata)
            jobFlags(Job.Flags)
            function(函数入口地址)(Job.ResumeTask)
            initialContext(AsyncTask.ResumeContext)
                偏移了headerSize的地址(大小是initialContextSize), 但它指向的空间这一步还未初始化, 具体在后面

        2. ChildFragment: 如果有parent, 直接在固定的内存地址使用构造方法

        3. GroupChildFragment: 如果有group, 直接在固定的内存地址使用构造方法

        4. 如果需要返回值
            FutureFragment:指定的内存位置调用构造函数
            FutureAsyncContextPrefix:
                function(公用的入口函数future_adapter)
                closureContext

        5. 如果不需要返回
            AsyncContextPrefix:
                function(公用的入口函数no_future_adapter)
                closureContext

        到这里AsyncTask其实还未初始化完毕:
            Private部分
            initialContext指向的空间
#endif

  SWIFT_TASK_DEBUG_LOG("creating task %p ID %" PRIu64
                       " with parent %p at base pri %zu",
                       task, task->getTaskId(), parent, basePriority);

  // Initialize the task-local allocator.
  initialContext->ResumeParent =
      runInlineOption ? &completeInlineTask
                      : reinterpret_cast<TaskContinuationFunction *>(
                            asyncLet         ? &completeTask
                            : closureContext ? &completeTaskWithClosure
                                             : &completeTaskAndRelease);
  if ((asyncLet || (runInlineOption && runInlineOption->getAllocation())) &&
      initialSlabSize > 0) {
    assert(parent || (runInlineOption && runInlineOption->getAllocation()));
      // allocation的大小是amountToAllocate, 但在分配它时可能还有预留的空间(initialSlabSize)
    void *initialSlab = (char*)allocation + amountToAllocate;
    task->Private.initializeWithSlab(basePriority, initialSlab,
                                     initialSlabSize);
  } else { // 没有预留的空间
    task->Private.initialize(basePriority);
  }

  // Perform additional linking between parent and child task.
    // 在父任务和子任务之间执行额外的链接。
  if (parent) {
    // If the parent was already cancelled, we carry this flag forward to the child.
      // 如果父任务已经取消, 将标记传递到子任务中
    //
    // In a task group we would not have allowed the `add` to create a child anymore,
    // however better safe than sorry and `async let` are not expressed as task groups,
    // so they may have been spawned in any case still.
      // 在任务组中，我们不再允许“add”创建子任务，但是安全总比后悔好，并且“async let”并未表示为任务组，因此无论如何它们可能仍然会被生成。
    if ((group && group->isCancelled()) || swift_task_isCancelled(parent))
      swift_task_cancel(task);

    // Inside a task group, we may have to perform some defensive copying,
    // check if doing so is necessary, and initialize storage using partial
    // defensive copies if necessary.
    if (group) {
      assert(parent && "a task created in a group must be a child task");
    }

    // Initialize task locals with a link to the parent task.
      // 使用指向父任务的链接初始化任务本地变量。
    //
    // Inside a task group, we may have to perform some defensive copying,
    // and initialize storage using partial defensive copies if necessary.
      // 在任务组内部，我们可能必须执行一些防御性复制，并在必要时使用部分防御性复制初始化存储。
    //
    // If we were going to copy ALL values anyway, we don't need to
    // perform this defensive partial copying. In practice, we currently
    // do not have child tasks which force copying, but we could.
      // 如果我们无论如何都要复制所有值，则无需执行这种防御性部分复制。实际上，我们目前没有强制复制的子任务，但我们可以。
    assert(!taskCreateFlags.copyTaskLocals() &&
           "Currently we don't have child tasks which force copying task "
           "locals; unexpected attempt to combine the two!");
      // 复制堆栈(parent到task)
    task->_private().Local.initializeLinkParent(task, parent);
  }

  // Configure the initial context.
  //
  // FIXME: if we store a null pointer here using the standard ABI for
  // signed null pointers, then we'll have to authenticate context pointers
  // as if they might be null, even though the only time they ever might
  // be is the final hop.  Store a signed null instead.
    // FIXME：如果我们使用有符号空指针的标准 ABI 在此处存储空指针，则我们必须对上下文指针进行验证，
    // 就好像它们可能为空一样，即使它们唯一可能为空的时间是最后一跳。请存储有符号空值。
  initialContext->Parent = nullptr;

  // FIXME: add discarding flag
  // FIXME: add task executor
  concurrency::trace::task_create(
      task, parent, group, asyncLet,
      static_cast<uint8_t>(task->Flags.getPriority()),
      task->Flags.task_isChildTask(), task->Flags.task_isFuture(),
      task->Flags.task_isGroupChildTask(), task->Flags.task_isAsyncLetTask());

  // Attach to the group, if needed.
  if (group) {
    swift_taskGroup_attachChild(group, task);
#if SWIFT_CONCURRENCY_TASK_TO_THREAD_MODEL
    // We need to take a retain here to keep the child task for the task group
    // alive. In the non-task-to-thread model, we'd always take this retain
    // below since we'd enqueue the child task. But since we're not going to be
    // enqueueing the child task in this model, we need to take this +1 to
    // balance out the release that exists after the task group child task
    // creation
    swift_retain(task);
#endif
  }

  // If we're supposed to copy task locals, do so now.
  if (taskCreateFlags.copyTaskLocals()) {
      // 复制cur-task的堆栈(这里其实是复制task的本地对象, 类比线程本地存储(thread_local))到task
    swift_task_localsCopyTo(task);
  }

  // Push the async let task status record.
  if (asyncLet) {
      // 这里初始化asyncLet的空间, 构造record, 加到当前线程的task->status中
    asyncLet_addImpl(task, asyncLet, !hasAsyncLetResultBuffer);
  }

  // Task executor preference
  // If the task does not have a specific executor set already via create
  // options, and there is a task executor preference set in the parent, we
  // inherit it by deep-copying the preference record. if
  // (shouldPushTaskExecutorPreferenceRecord || taskExecutor.isDefined()) 
    // 任务执行器偏好 如果任务尚未通过创建选项设置特定的执行器，并且父级中设置了任务执行器偏好，则我们通过深度复制偏好记录来继承它。
  if (jobFlags.task_hasInitialTaskExecutorPreference()) {
    // Implementation note: we must do this AFTER `swift_taskGroup_attachChild`
    // because the group takes a fast-path when attaching the child record.
    assert(jobFlags.task_hasInitialTaskExecutorPreference());
      // 在当前task上创建record
    task->pushInitialTaskExecutorPreference(
        taskExecutor, /*owned=*/taskExecutorIsOwned);
  }

  // If we're supposed to enqueue the task, do so now.
  if (taskCreateFlags.enqueueJob()) {
#if SWIFT_CONCURRENCY_TASK_TO_THREAD_MODEL
    assert(false && "Should not be enqueuing tasks in task-to-thread model");
#endif
    swift_retain(task);
    task->flagAsAndEnqueueOnExecutor(
        serialExecutor);
  }

  return {task, initialContext};
}
```

整个异步任务的创建过程比较复杂, 总结起来:
1. 开辟了一大块内存
2. 该内存的前半部分是AsyncTask, 在该空间中记录了函数的启动地址(non_future_adapter), 再由这个统一的中转函数进入到用户代码
3. 该内存的后半部分是上下文地址, 往上偏移固定的大小可以得到non_future_adapter

其中编译器最初传递的入口地址可以被准确定位到. 接下来就是`swift_job_run`, 它的作用是在给定的executor上执行对应的task

```cpp
// 由swift_job_run调用(参数不会发生变化)
// job即为前面创建的 x0
// 第2个参数传递的是 {gcd_main_q, 实现}
SWIFT_CC(swift)
static void swift_job_runImpl(Job *job, SerialExecutorRef executor) {
  ExecutorTrackingInfo trackingInfo;

  // swift_job_run is a primary entrypoint for executors telling us to
  // run jobs.  Actor executors won't expect us to switch off them
  // during this operation.  But do allow switching if the executor
  // is generic.
  // 这个判断实际就是 executor.Identity != nullptr, 即 gcd_main_q != nullptr是成立的
  // 所以设置 不允许切换的标记为false
  if (!executor.isGeneric()) trackingInfo.disallowSwitching();

  auto taskExecutor = executor.isGeneric()
                          ? TaskExecutorRef::fromTaskExecutorPreference(job)
                          : TaskExecutorRef::undefined();

    // 切换当前线程的executor, 记录下旧值
  trackingInfo.enterAndShadow(executor, taskExecutor);

  SWIFT_TASK_DEBUG_LOG("job %p", job);
  // 直接在当前线程上运行任务
  //  task->ResumeTask(ResumeContext)
  // 而ResumeTask就是 swift_task_create中初始化的no_future_adapter函数,
  // 进入到该函数后就相当于进入到了 异步main函数(用户的main函数被拆分了)
  runJobInEstablishedExecutorContext(job);

  trackingInfo.leave();

  // Give up the current executor if this is a switching context
  // (which, remember, only happens if we started out on a generic
  // executor) and we've switched to a default actor.
  auto currentExecutor = trackingInfo.getActiveExecutor();
  if (trackingInfo.allowsSwitching() && currentExecutor.isDefaultActor()) {
    asImpl(currentExecutor.getDefaultActor())->unlock(true);
  }
}
```

指令执行到`non_future_adapter`后, 后面就会进入到用户的main函数, 但其实main函数本身会被拆分成几个部分
```cpp
// 由前面调用来
//  SWIFT_ASYNC_CONTEXT 告诉llvm这个参数使用x22寄存器传值
// 实际上 _context就是swift_task_create的initialContext, 它和当前任务的地址相差0x100字节(汇编调试), 但在同一块内存中
static void non_future_adapter(SWIFT_ASYNC_CONTEXT AsyncContext *_context) {
  auto asyncContextPrefix = reinterpret_cast<AsyncContextPrefix *>(
      reinterpret_cast<char *>(_context) - sizeof(AsyncContextPrefix));
  return asyncContextPrefix->asyncEntryPoint(
      _context, asyncContextPrefix->closureContext);
} 
```

这里实际就取出了用户最早传递的异步函数入口(还未进入到用户的main代码):

```lua
// x22: ctx
swift`partial apply for thunk for @escaping @convention(thin) @async () -> ():
->  0x100003c00 <+0>:   orr    x29, x29, #0x1000000000000000    ; 异步函数独有的操作(根据测试x29在arm64上并未发生改变)
    0x100003c04 <+4>:   sub    sp, sp, #0x40                    
    0x100003c08 <+8>:   stp    x29, x30, [sp, #0x30]
    0x100003c0c <+12>:  str    x22, [sp, #0x28]         ; 在完全建立堆栈前, 先存储 ctx, *(sp + 0x28) = ctx
    0x100003c10 <+16>:  add    x29, sp, #0x30           ; 完全建立堆栈
    0x100003c14 <+20>:  stur   x0, [x29, #-0x10]                
    0x100003c18 <+24>:  mov    x8, x22                          
    0x100003c1c <+28>:  str    x8, [sp]                 ; *sp = ctx
    0x100003c20 <+32>:  mov    x22, x8                          
    0x100003c24 <+36>:  str    x22, [x8, #0x10]         ; (*ctx)<0x10(16) ~ 0x17(23)bit> = ctx
    0x100003c28 <+40>:  ldr    x8, [x20, #0x10]         ;           
    0x100003c2c <+44>:  str    x8, [sp, #0x18]          ; *(sp + 0x18) = 0x0000000100008000(async_MainTu, 由汇编测试)
    0x100003c30 <+48>:  adrp   x8, 5
    0x100003c34 <+52>:  str    x8, [sp, #0x8]           ; *(sp + 8) = 0x100008000(全局对象的地址 async_MainTu)
    0x100003c38 <+56>:  adrp   x8, 5
    0x100003c3c <+60>:  add    x8, x8, #0x8             ; async function pointer to reabstraction thunk helper from @escaping @convention(thin) @async () -> () to @escaping @callee_guaranteed @async () -> (@out (), @error @owned Swift.Error)
                                                        ; x8 = 0x100008008
    0x100003c40 <+64>:  str    x8, [sp, #0x10]          ; *(sp + 0x10) = 0x100008008
    0x100003c44 <+68>:  ldr    w8, [x8, #0x4]           ; 获取大小(上下文)
    0x100003c48 <+72>:  mov    x0, x8
    0x100003c4c <+76>:  bl     0x100003f18              ; symbol stub for: swift_task_alloc, 分配上下文
                                                        ; 参数x0:  大小
                                                        ; 返回x0: ctx-1
    0x100003c50 <+80>:  ldr    x10, [sp]                ; x10 = ctx
    0x100003c54 <+84>:  ldr    x9, [sp, #0x8]           ; x9 = async_MainTu
    0x100003c58 <+88>:  ldr    x8, [sp, #0x10]          ; x8 = 0x100008008
    0x100003c5c <+92>:  ldr    x1, [sp, #0x18]          ; x1 = async_MainTu
    0x100003c60 <+96>:  mov    x22, x0
    0x100003c64 <+100>: ldur   x0, [x29, #-0x10]
    0x100003c68 <+104>: mov    x11, x22
    0x100003c6c <+108>: str    x11, [x10, #0x18]
    0x100003c70 <+112>: ldr    x10, [x10, #0x10]
    0x100003c74 <+116>: str    x10, [x22]
    0x100003c78 <+120>: adrp   x10, 0
    0x100003c7c <+124>: add    x10, x10, #0xc9c          ; (1) await resume partial function for partial apply forwarder for reabstraction thunk helper from @escaping @convention(thin) @async () -> () to @escaping @callee_guaranteed @async () -> (@out (), @error @owned Swift.Error) at <compiler-generated>
    0x100003c80 <+128>: str    x10, [x22, #0x8]
    0x100003c84 <+132>: ldrsw  x9, [x9, #0x8]
    0x100003c88 <+136>: add    x2, x8, x9
    0x100003c8c <+140>: ldp    x29, x30, [sp, #0x30]
    0x100003c90 <+144>: and    x29, x29, #0xefffffffffffffff
    0x100003c94 <+148>: add    sp, sp, #0x40
    0x100003c98 <+152>: br     x2
```





### AsyncTask
在swift并发中一个比较重要的结构是AsyncTask, 它是异步任务的入口:
1. 每个异步函数内部出现了`async let`会就地创建一个异步任务
2. 每个异步函数内部出现了`Task`会就地创建一个异步任务
3. 每个异步任务在执行时会绑定线程, 在被调度时可能又会绑定到其他线程(<font color = red>这种绑定由swift用户态决定</font>)
4. 每个异步任务由若干个上下文(AsyncContext)构成, 每个上下文有自己独立的堆栈(替代函数参数和函数局部对象), 结果存储, 它们之间的顺序决定了整个异步任务的执行顺序






### 异步函数的参数


### 异步函数的局部对象


### swift的线程对象
 




### 结构化并发1
先来看一个测试
```swift
func f4() -> Int {
    print("f4()<\(pthread_self())>")
    return 20
}

func f3() async -> Int {
    print("f3()<\(pthread_self())>")
    try? await Task.sleep(nanoseconds: UInt64(1e9))
    return f4();
}

func f2() async -> Int {
    print("f2()<\(pthread_self())>")
    try? await Task.sleep(nanoseconds: UInt64(1e9))
    return await f3()
}

func f1() async -> Int {
    print("f1()<\(pthread_self())>")
    try? await Task.sleep(nanoseconds: UInt64(1e9))
    return await f2()
}

print("main<\(pthread_self())>")
let no = await f1()
print(no)

#if compiler(<0)
main<0x00000001ec77f840>
f1()<0x000000016fe87000>
f2()<0x000000016ff13000>
f3()<0x000000016fe87000>
f4()<0x000000016ff13000>
20
#endif
```

从测试结果可以得出这几个结论(<font color = red>多次测试笔者就不贴出测试结果了</font>):
1. 异步函数会分配线程(<font color = red>可能分配, 因为底层依赖了gcd, 线程由gcd维护</font>)
2. 异步函数的调用有固定的语法格式(<font color = red>await</font>)
3. 发起await的调用会等待它执行完毕

因为第3个原因, 所以虽然4个函数分配了随机的线程, 但整个程序的执行是顺序的. 为了说明async和await的实现原理, 需要深入到swift的源码. 


### 测试代码1
```swift
nonisolated(unsafe) var A = 20, B = 30  // __code_main_user_0

func f3(a: Int) async -> Int {
    return a;
}

func f2(a: Int)async -> Int {
    let n = await f3(a: a)
    return n
}

func f(a: Int) async throws -> Int {
    var number = a + 20
    number = await f2(a: number)
    return number
}

func f() async throws -> Int {
    return await f2(a: 20)
}
A = try! await f(a: B)      // __code_main_user_1
```

整个代码在main函数的区域中书写, 因为产生了await的调用, 所以真正的main函数其实是被处理成了异步函数, 而swift中异步函数本身被拆分成多个函数, 笔者现在简单说一下这个过程:
1. swift程序被启动
2. 系统的start函数(Mac系统上)启动
3. start调用main函数, 这个main函数并不是用户书写的main, 而是编译器生成的main函数(<font color = red>简称Main</font>), 它主要的作用是初始化异步环境, 引导进入到用户的main函数
4. Main中创建AsyncTask对象(`swift_task_create`)
5. Main中调用`swift_job_run`
6. `swift_job_run`后续中间省略一些, 进入到`future_adapter`函数
7. 再进入到main的拆分函数main-0
8. 再进入到用户书写的main环境中, 即在主线程执行`__code_main_user_0`
10. 执行`__code_main_user_1`
11. 因为发起了await调用, 所以创建上下文(AsyncContext)
12. 进入到f这个异步函数的拆分部分f-0
13. f-0中创建上下文, 接着进入f2-0
14. f2-0中创建上下文, 进入到f3, 因为f3虽然是异步函数, 但实现中f3并不具备暂停点, 所以相当于普通函数


### 过程3(汇编Main)
```lua
swift`main:
    0x100003674 <+0>:   sub    sp, sp, #0x20
    0x100003678 <+4>:   stp    x29, x30, [sp, #0x10]
    0x10000367c <+8>:   add    x29, sp, #0x10
    0x100003680 <+12>:  adrp   x8, 1                    ; x8 = 0x100004000
    0x100003684 <+16>:  add    x8, x8, #0x70           
    0x100003688 <+20>:  add    x0, x8, #0x10            ; x0 = 0x100004080
    0x10000368c <+24>:  mov    w8, #0x18                  =24 
    0x100003690 <+28>:  mov    x1, x8                   ; x1 = 24
    0x100003694 <+32>:  mov    w8, #0x7                 ; =7 
    0x100003698 <+36>:  mov    x2, x8                   ; x2 = 7
    0x10000369c <+40>:  bl     0x100003ec0              ; symbol stub for: swift_allocObject
                                                        ;   x0: metadata
                                                        ;   x1: 需要的大小
                                                        ;   x2: requiredAlignmentMask(这里不关心这个参数)
                                                        ; x0 = ctx
    0x1000036a0 <+44>:  mov    x4, x0                   ; x4 = ctx
    0x1000036a4 <+48>:  adrp   x8, 5                    ; 
    0x1000036a8 <+52>:  add    x8, x8, #0x0             ; async_MainTu, x8 = 0x100008000(全局对象)
    0x1000036ac <+56>:  str    x8, [x4, #0x10]          ; *(heap + 0x10) = async_MainTu
    0x1000036b0 <+60>:  mov    w8, #0x800               ; =2048 
    0x1000036b4 <+64>:  mov    x0, x8                   ; x0 = 0x800,                                
    0x1000036b8 <+68>:  mov    x1, #0x0                 ; x1 = 0      
    0x1000036bc <+72>:  adrp   x8, 1                        
    0x1000036c0 <+76>:  ldr    x8, [x8]                 ; x8 = 0x00000001ee890650, "()"的metadata
    0x1000036c4 <+80>:  add    x2, x8, #0x8             ; x2 = ().metadata + 8
    0x1000036c8 <+84>:  adrp   x3, 5
    0x1000036cc <+88>:  add    x3, x3, #0x10            ; async function pointer to partial apply forwarder for reabstraction thunk helper from @escaping @convention(thin) @async () -> () to @escaping @callee_guaranteed @async () -> (@out (), @error @owned Swift.Error)
->  0x1000036d0 <+92>:  bl     0x100003f14              ; symbol stub for: swift_task_create
                                                        ; x0: TaskCreateFlags.Task_EnqueueJob
                                                        ; x1: nullptr
                                                        ; x2: ().metadata + 8, 即空元组.metadata + 8
                                                        ; x3: 0x0000000100008010, 用户main函数代码的拆分main-0函数
                                                        ; x4: 上下文(ctx)
                                                        ;   函数返回 {AsyncTask*(x0),AsyncContext*(x1)}

    0x1000036d4 <+96>:  str    x0, [sp]                 ; *sp = AsyncTask*(x0)
    0x1000036d8 <+100>: bl     0x100003f2c              ; symbol stub for: swift_task_getMainExecutor
                                                        ; 返回{SerialExecutorRef.Identity(gcd_main_q), SerialExecutorRef.Implementation(实现)}
                                                        
    0x1000036dc <+104>: mov    x2, x0
    0x1000036e0 <+108>: ldr    x0, [sp]
    0x1000036e4 <+112>: str    x2, [sp, #0x8]
    0x1000036e8 <+116>: mov    x2, x1
    0x1000036ec <+120>: ldr    x1, [sp, #0x8]
    0x1000036f0 <+124>: bl     0x100003ef0              ; symbol stub for: swift_job_run
                                                        ; 启动Task, 具体看后续源码

    0x1000036f4 <+128>: bl     0x100003f08              ; symbol stub for: swift_task_asyncMainDrainQueue
                                                        ; 启动runloop, 主线程等待唤醒
    0x1000036f8 <+132>: brk    #0x1 
```


### 过程4(源码`swift_task_create`)
```cpp
/// Flags for task creation.
class TaskCreateFlags : public FlagSet<size_t> {
public:
  enum {
    // Priority that user specified while creating the task
      // 对应Job的优先级(JobPriority), 前8个bit位是互斥的
    RequestedPriority = 0,
    RequestedPriority_width = 8,

      // 后面的bit位是位或(共存)
    Task_IsChildTask                              = 8,
    // Should only be set in task-to-thread model where Task.runInline is
    // available
    Task_IsInlineTask                             = 9,
    Task_CopyTaskLocals                           = 10,
    Task_InheritContext                           = 11,
    Task_EnqueueJob                               = 12,
    Task_AddPendingGroupTaskUnconditionally       = 13,
    Task_IsDiscardingTask                         = 14,
  };

  // ...  都是这些bit位的setter和getter
  // FlagSet是一个通用的bit操作类
};

#if 0
参数0: 由swift传递, 它是动态的, 是swift在编译我们书写的代码时, 得出的结果, 每个不同场景可能对应的结果不一样, 发起调用时传递的值就不一样
参数1: 由swift提供, 这里是nullptr
参数2: 异步函数的结果, 对应的是swift中的类型, 如Int, String, Tuple等, 这里是tuple, 即"()"
参数3: 闭包, 这里是main函数的拆分main-0函数
参数4: 闭包需要的上下文
#endif 
SWIFT_CC(swift)
AsyncTaskAndContext swift::swift_task_create(
    size_t rawTaskCreateFlags,  
    TaskOptionRecord *options,
    const Metadata *futureResultType,
    void *closureEntry, HeapObject *closureContext) {
  TaskCreateFlags taskCreateFlags(rawTaskCreateFlags);

  if (taskCreateFlags.isDiscardingTask()) {
      // 如果task的结果是被丢弃的, 则taskEntry ==> void(*)(AsyncContext*)
    ThinNullaryAsyncSignature::FunctionType *taskEntry;
    size_t initialContextSize; // 异步上下文大小

      // closureEntry由swift创建,
      //    根据后续的源码, 能进入到这个if, 说明它的类型是 AsyncFunctionPointer<AsyncSignature<void(), false>>*
      //    将 closureEntry 还原, 取出函数的入口和函数的上下文大小
    std::tie(taskEntry, initialContextSize) =
      getAsyncClosureEntryPointAndContextSize<
        ThinNullaryAsyncSignature,
        SpecialPointerAuthDiscriminators::AsyncThinNullaryFunction>(closureEntry); 

      // swift_task_create_common最终会调用到swift_task_create_commonImpl
    return swift_task_create_common(
        rawTaskCreateFlags, options, futureResultType,
        reinterpret_cast<TaskContinuationFunction *>(taskEntry), closureContext,
        initialContextSize);

    // 根据参数的值, 会到这里来转换
  } else {
      // taskEntry ==> void(*)(void*)
    FutureAsyncSignature::FunctionType *taskEntry;
    size_t initialContextSize;

    std::tie(taskEntry, initialContextSize) =
        getAsyncClosureEntryPointAndContextSize<
            FutureAsyncSignature,
            SpecialPointerAuthDiscriminators::AsyncFutureFunction>(closureEntry);

    return swift_task_create_common(
        rawTaskCreateFlags, options, futureResultType,
        reinterpret_cast<TaskContinuationFunction *>(taskEntry), closureContext,
        initialContextSize);
  }
}




/// Implementation of task creation.
SWIFT_CC(swift)
static AsyncTaskAndContext
swift_task_create_commonImpl(size_t rawTaskCreateFlags,
                             TaskOptionRecord *options,
                             const Metadata *futureResultTypeMetadata,
                             TaskContinuationFunction *function, /*void(AsyncContext*)*/
                             void *closureContext, size_t initialContextSize) {

    // 复制task标记
  TaskCreateFlags taskCreateFlags(rawTaskCreateFlags);

    // 作业标记(Job)
    //  初始化: Kind = 0(Task)
    //         Priority = 0(UN),
    //         剩余bit是0
    //  后面是根据情况会修改相关的bit位
  JobFlags jobFlags(JobKind::Task, JobPriority::Unspecified);

  // Propagate task-creation flags to job flags as appropriate.
    // 如果外界的语义造成了要创建子task(编译器识别后做的标记), 这里就直接标记job
  jobFlags.task_setIsChildTask(taskCreateFlags.isChildTask());

    // 返回值的类型
  ResultTypeInfo futureResultType;
  #if !SWIFT_CONCURRENCY_EMBEDDED
  futureResultType.metadata = futureResultTypeMetadata;
  #endif

  // Collect the options we know about.
  SerialExecutorRef serialExecutor = SerialExecutorRef::generic();
  TaskExecutorRef taskExecutor = TaskExecutorRef::undefined();
  bool taskExecutorIsOwned = false;
  TaskGroup *group = nullptr;
  AsyncLet *asyncLet = nullptr;
  bool hasAsyncLetResultBuffer = false;
  RunInlineTaskOptionRecord *runInlineOption = nullptr;
  for (auto option = options; option; option = option->getParent()) {
    switch (option->getKind()) {
           // 串行执行器
    case TaskOptionRecordKind::InitialSerialExecutor:
      serialExecutor = cast<InitialSerialExecutorTaskOptionRecord>(option)
                          ->getExecutorRef();
      break;

    case TaskOptionRecordKind::InitialTaskExecutorUnowned:
      taskExecutor = cast<InitialTaskExecutorRefPreferenceTaskOptionRecord>(option)
                         ->getExecutorRef();
      jobFlags.task_setHasInitialTaskExecutorPreference(true);
      taskExecutorIsOwned = false;
      break;

    case TaskOptionRecordKind::InitialTaskExecutorOwned:
      #if SWIFT_CONCURRENCY_EMBEDDED
      swift_unreachable("owned TaskExecutor cannot be used in embedded Swift");
      #else
      taskExecutor = cast<InitialTaskExecutorOwnedPreferenceTaskOptionRecord>(option)
                         ->getExecutorRefFromUnownedTaskExecutor();
      taskExecutorIsOwned = true;
      jobFlags.task_setHasInitialTaskExecutorPreference(true);
      #endif
      break;

    case TaskOptionRecordKind::TaskGroup:
      group = cast<TaskGroupTaskOptionRecord>(option)->getGroup();
      assert(group && "Missing group");
      jobFlags.task_setIsGroupChildTask(true);
      break;

    case TaskOptionRecordKind::AsyncLet:
      asyncLet = cast<AsyncLetTaskOptionRecord>(option)->getAsyncLet();
      assert(asyncLet && "Missing async let storage");
      jobFlags.task_setIsAsyncLetTask(true);
      jobFlags.task_setIsChildTask(true);
      break;

    case TaskOptionRecordKind::AsyncLetWithBuffer: {
      auto *aletRecord = cast<AsyncLetWithBufferTaskOptionRecord>(option);
      asyncLet = aletRecord->getAsyncLet();
      // TODO: Actually digest the result buffer into the async let task
      // context, so that we can emplace the eventual result there instead
      // of in a FutureFragment.
      hasAsyncLetResultBuffer = true;
      assert(asyncLet && "Missing async let storage");

      jobFlags.task_setIsAsyncLetTask(true);
      jobFlags.task_setIsChildTask(true);
      break;
    }
    case TaskOptionRecordKind::RunInline: {
      runInlineOption = cast<RunInlineTaskOptionRecord>(option);
      // TODO (rokhinip): We seem to be creating runInline tasks like detached
      // tasks but they need to maintain the voucher and priority of calling
      // thread and therefore need to behave a bit more like SC child tasks.
      break;
    }
    case TaskOptionRecordKind::ResultTypeInfo: {
#if SWIFT_CONCURRENCY_EMBEDDED
      auto *typeInfo = cast<ResultTypeInfoTaskOptionRecord>(option);
      futureResultType = {
          .size = typeInfo->size,
          .alignMask = typeInfo->alignMask,
          .initializeWithCopy = typeInfo->initializeWithCopy,
          .storeEnumTagSinglePayload = typeInfo->storeEnumTagSinglePayload,
          .destroy = typeInfo->destroy,
      };
      break;
#else
      swift_unreachable("ResultTypeInfo in non-embedded");
#endif
    }
    }
  }

  #if SWIFT_CONCURRENCY_EMBEDDED
  assert(!futureResultType.isNull());
  #endif

    // 标记job的返回值
  if (!futureResultType.isNull()) {
    jobFlags.task_setIsFuture(true);
    assert(initialContextSize >= sizeof(FutureAsyncContext));
  }
    // 实际的汇编调试中这里是TLS(线程的本地存储)机制,
    //  可能取到的是空, 如这种情况
    //      > main函数中
    //      >  func test() async {}
    //      >  await test()
    //  此刻编译器会将程序的main进行拆分, 在真正进入到 try await test()前, 会经过很多中转函数才会来到这里, 这些函数由编译器配合swift的并发机制一同实现
  AsyncTask *currentTask = swift_task_getCurrent();
    // 有3种情况jobFlags的isChildTask置位
    //  > taskCreateFlags.isChildTask == true
    //  > parent中有类型是AsyncLet
    //  > parent中有类型是AsyncLetWithBuffer
  AsyncTask *parent = jobFlags.task_isChildTask() ? currentTask : nullptr;

  if (group) {
    assert(parent && "a task created in a group must be a child task");
    // Add to the task group, if requested.
    if (taskCreateFlags.addPendingGroupTaskUnconditionally()) {
      assert(group && "Missing group");
      swift_taskGroup_addPending(group, /*unconditionally=*/true);
    }
  }

  // Start with user specified priority at creation time (if any)
    // 根据taskCreateFlags以及jobFlags的不同指定不同的Job优先级
  JobPriority basePriority = (taskCreateFlags.getRequestedPriority());

  if (taskCreateFlags.isInlineTask()) {
      // 如果当前想要创建inline-task, 取当前线程的优先级(Mac平台则会使用Dispatch.Oos)
     SWIFT_TASK_DEBUG_LOG("Creating an inline task from %p", currentTask);

     // We'll take the current priority and set it as base and escalated
     // priority of the task. No UI->IN downgrade needed.
     basePriority = swift_task_getCurrentThreadPriority();

  } else if (taskIsDetached(taskCreateFlags, jobFlags)) {
      //    job.not_contain(task_isAsyncLetTask) &&
      //    job.not_contain(task_isGroupChildTask) &&
      //    task.not_contain(copyTaskLocals) &&
      //    task.not_contain(isInlineTask)
     SWIFT_TASK_DEBUG_LOG("Creating a detached task from %p", currentTask);
     // Case 1: No priority specified
     //    Base priority = UN
     //    Escalated priority = UN
     // Case 2: Priority specified
     //    Base priority = user specified priority
     //    Escalated priority = UN
     //
     // Task will be created with max priority = max(base priority, UN) = base
     // priority. We shouldn't need to do any additional manipulations here since
     // basePriority should already be the right value
      // 不需要做额外的操作, 因为此时basePriority应该已经是正常值


  } else if (taskIsUnstructured(taskCreateFlags, jobFlags)) { // 非结构化
      //    job.not_contain(task_isAsyncLetTask) &&
      //    job.not_contain(task_isGroupChildTask) &&
      //    task.not_contain(isInlineTask)
     SWIFT_TASK_DEBUG_LOG("Creating an unstructured task from %p", currentTask);

    if (isUnspecified(basePriority)) {
      // Case 1: No priority specified
      //    Base priority = Base priority of parent with a UI -> IN downgrade
      //    Escalated priority = UN
      if (currentTask) { // 继承当前task的优先级
        basePriority = currentTask->_private().BasePriority;
      } else {          // 继承当前线程的优先级
        basePriority = swift_task_getCurrentThreadPriority();
      }
        // 最高为UI
      basePriority = withUserInteractivePriorityDowngrade(basePriority);
    } else {
      // Case 2: User specified a priority
      //    Base priority = user specified priority
      //    Escalated priority = UN
    }

    // Task will be created with max priority = max(base priority, UN) = base
    // priority
  } else { // 结构化的task
    // Is a structured concurrency child task. Must have a parent.
    assert((asyncLet || group) && parent);
    SWIFT_TASK_DEBUG_LOG("Creating an structured concurrency task from %p", currentTask);

    if (isUnspecified(basePriority)) {
      // Case 1: No priority specified
      //    Base priority = Base priority of parent with a UI -> IN downgrade
      //    Escalated priority = Escalated priority of parent with a UI -> IN
      //    downgrade
      JobPriority parentBasePri = parent->_private().BasePriority;
      basePriority = withUserInteractivePriorityDowngrade(parentBasePri);
    } else {
      // Case 2: User priority specified
      //    Base priority = User specified priority
      //    Escalated priority = Escalated priority of parent with a UI -> IN
      //    downgrade
    }

    // Task will be created with escalated priority = base priority. We will
    // update the escalated priority with the right rules in
    // updateNewChildWithParentAndGroupState when we link the child into
    // the parent task/task group since we'll have the right
    // synchronization then.
  }

  if (isUnspecified(basePriority)) {
     basePriority = JobPriority::Default;
  }// 优先级判断完毕

  SWIFT_TASK_DEBUG_LOG("Task's base priority = %#zx", basePriority);

    // 计算大小
    //  实际空间在逻辑上分为这几部分(0开始加):
    //  1. += AsyncTask
    //  2. += ChildFragment
    //  3. += GroupChildFragment
    //  4. += 如果需要接收返回值 ? (fragmentSize + FutureAsyncContextPrefix) : AsyncContextPrefix
    //  5. 对齐到16的倍数, 此刻是headerSize
    //  6. += initialContextSize (amountToAllocate, 16倍数)
  size_t headerSize, amountToAllocate;
  std::tie(headerSize, amountToAllocate) = amountToAllocateForHeaderAndTask(
      parent, group, futureResultType, initialContextSize);

  unsigned initialSlabSize = 512;

  void *allocation = nullptr;
  if (asyncLet) {
    assert(parent);

    // If there isn't enough room in the fixed async let allocation to
    // set up the initial context, then we'll have to allocate more space
    // from the parent.
    if (asyncLet->getSizeOfPreallocatedSpace() < amountToAllocate) {
      hasAsyncLetResultBuffer = false;
    }

    // DEPRECATED. This is separated from the above condition because we
    // also have to handle an older async let ABI that did not provide
    // space for the initial slab in the compiler-generated preallocation.
    if (!hasAsyncLetResultBuffer) {
        // 返回到外界的指针类型是void*, 但实际返回的是 Allocation*,
        // 但偏移了16字节
      allocation = _swift_task_alloc_specific(parent,
                                          amountToAllocate + initialSlabSize);
    } else {
        // 真实的指针:AsyncLet(640字节)*, 但对于AsyncLet*的实现中头部有80字节(AsyncLetImpl*),
        //  返回到这里的指针(allocation)偏移了sizeof(AsyncLetImpl)(80字节),
        //  这个对于外界来说实际是数据开始的地址
      allocation = asyncLet->getPreallocatedSpace();
      assert(asyncLet->getSizeOfPreallocatedSpace() >= amountToAllocate
             && "async let does not preallocate enough space for child task");

        // 560字节 - amountToAllocate 必须 >= 0
      initialSlabSize = asyncLet->getSizeOfPreallocatedSpace()
                          - amountToAllocate;
    }
  } else if (runInlineOption && runInlineOption->getAllocation()) {
    // NOTE: If the space required for the task and initial context was
    //       greater than SWIFT_TASK_RUN_INLINE_INITIAL_CONTEXT_BYTES,
    //       getAllocation will return nullptr and we'll fall back to malloc to
    //       allocate the buffer.
    //
    // This was already checked in swift_task_run_inline.
    size_t runInlineBufferBytes = runInlineOption->getAllocationBytes();
    assert(amountToAllocate <= runInlineBufferBytes);
    allocation = runInlineOption->getAllocation();
    initialSlabSize = runInlineBufferBytes - amountToAllocate;
  } else {
    allocation = malloc(amountToAllocate);
  }
  SWIFT_TASK_DEBUG_LOG("allocate task %p, parent = %p, slab %u", allocation,
                       parent, initialSlabSize);

  AsyncContext *initialContext =
    reinterpret_cast<AsyncContext*>(
      reinterpret_cast<char*>(allocation) + headerSize);

  //  We can't just use `function` because it uses the new async function entry
  //  ABI -- passing parameters, closure context, indirect result addresses
  //  directly -- but AsyncTask->ResumeTask expects the signature to be
  //  `void (*, *, swiftasync *)`.
  //  Instead we use an adapter. This adaptor should use the storage prefixed to
  //  the async context to get at the parameters.
  //  See e.g. FutureAsyncContextPrefix.
    // 我们不能只使用 `function`，因为它使用新的异步函数入口ABI——直接传递参数、闭包上下文、间接结果地址——但 AsyncTask->ResumeTask 期望签名为 `void (*, *, swiftasync *)`。
    // 相反，我们使用适配器。此适配器应使用以异步上下文为前缀的存储来获取参数。
    // 例如，参见 FutureAsyncContextPrefix。

  if (futureResultType.isNull() || taskCreateFlags.isDiscardingTask()) {
    auto asyncContextPrefix = reinterpret_cast<AsyncContextPrefix *>(
        reinterpret_cast<char *>(allocation) + headerSize -
        sizeof(AsyncContextPrefix));
    asyncContextPrefix->asyncEntryPoint =
        reinterpret_cast<AsyncVoidClosureEntryPoint *>(function);
    asyncContextPrefix->closureContext = closureContext;
    function = non_future_adapter;
    assert(sizeof(AsyncContextPrefix) == 3 * sizeof(void *));
  } else {
    auto asyncContextPrefix = reinterpret_cast<FutureAsyncContextPrefix *>(
        reinterpret_cast<char *>(allocation) + headerSize -
        sizeof(FutureAsyncContextPrefix));
    asyncContextPrefix->asyncEntryPoint =
        reinterpret_cast<AsyncGenericClosureEntryPoint *>(function);
    function = future_adapter;
    asyncContextPrefix->closureContext = closureContext;
    assert(sizeof(FutureAsyncContextPrefix) == 4 * sizeof(void *));
  }

  // Only attempt to inherit parent's executor preference if we didn't set one
  // explicitly, which we've recorded in the flag by noticing a task create
  // option higher up in this func.
  if (!jobFlags.task_hasInitialTaskExecutorPreference()) {
    // do we have a parent we can inherit the task executor from?
    if (parent) {
      auto parentTaskExecutor = parent->getPreferredTaskExecutor();
      if (parentTaskExecutor.isDefined()) {
        jobFlags.task_setHasInitialTaskExecutorPreference(true);
        taskExecutor = parentTaskExecutor;
      }
    }
  }

  // Initialize the task so that resuming it will run the given
  // function on the initial context.
  AsyncTask *task = nullptr;
    // 不是分离的任务需要凭证(要等待)
  bool captureCurrentVoucher = !taskIsDetached(taskCreateFlags, jobFlags);
  if (asyncLet) {
    // Initialize the refcount bits to "immortal", so that
    // ARC operations don't have any effect on the task.
    task = new (allocation)
        AsyncTask(taskHeapMetadataPtr, InlineRefCounts::Immortal, jobFlags,
                  function, initialContext, captureCurrentVoucher);
  } else {
    task = new (allocation) AsyncTask(taskHeapMetadataPtr, jobFlags, function,
                                      initialContext, captureCurrentVoucher);
  }

  // Initialize the child fragment if applicable.
  if (parent) {
    auto childFragment = task->childFragment();
    ::new (childFragment) AsyncTask::ChildFragment(parent);
  }

  // Initialize the group child fragment if applicable.
  if (group) {
    auto groupChildFragment = task->groupChildFragment();
    ::new (groupChildFragment) AsyncTask::GroupChildFragment(group);
  }

  // Initialize the future fragment if applicable.
  if (!futureResultType.isNull()) {
    assert(task->isFuture());
    auto futureFragment = task->futureFragment();
    ::new (futureFragment) FutureFragment(futureResultType);

    // Set up the context for the future so there is no error, and a successful
    // result will be written into the future fragment's storage.
    auto futureAsyncContextPrefix =
        reinterpret_cast<FutureAsyncContextPrefix *>(
            reinterpret_cast<char *>(allocation) + headerSize -
            sizeof(FutureAsyncContextPrefix));
    futureAsyncContextPrefix->indirectResult = futureFragment->getStoragePtr();
  }
#if 0
    AsyncTask的过程:
        1. 根据编译器提供参数
        2. 确定parent(有AsyncLet或AsyncLetWithBuffer或外界直接指定childTask)
        3. 确定group
        4. 确定futureResultType
        5. 确定优先级
        6. 分配内存(计算大小)
        7. 构造AsyncTask
        8. 初始化AsyncTask的空间
        9. 初始化其他相关部分
    AsyncTask空间的内容(headerSize部分)
        1. AsyncTask: 使用构造方法初始化
            taskHeapMetadataPtr(Job.metadata)
            jobFlags(Job.Flags)
            function(函数入口地址)(Job.ResumeTask)
            initialContext(AsyncTask.ResumeContext)
                偏移了headerSize的地址(大小是initialContextSize), 但它指向的空间这一步还未初始化, 具体在后面

        2. ChildFragment: 如果有parent, 直接在固定的内存地址使用构造方法

        3. GroupChildFragment: 如果有group, 直接在固定的内存地址使用构造方法

        4. 如果需要返回值
            FutureFragment:指定的内存位置调用构造函数
            FutureAsyncContextPrefix:
                function(公用的入口函数future_adapter)
                closureContext

        5. 如果不需要返回
            AsyncContextPrefix:
                function(公用的入口函数no_future_adapter)
                closureContext

        到这里AsyncTask其实还未初始化完毕:
            Private部分
            initialContext指向的空间
#endif

  SWIFT_TASK_DEBUG_LOG("creating task %p ID %" PRIu64
                       " with parent %p at base pri %zu",
                       task, task->getTaskId(), parent, basePriority);

  // Initialize the task-local allocator.
  initialContext->ResumeParent =
      runInlineOption ? &completeInlineTask
                      : reinterpret_cast<TaskContinuationFunction *>(
                            asyncLet         ? &completeTask
                            : closureContext ? &completeTaskWithClosure
                                             : &completeTaskAndRelease);
  if ((asyncLet || (runInlineOption && runInlineOption->getAllocation())) &&
      initialSlabSize > 0) {
    assert(parent || (runInlineOption && runInlineOption->getAllocation()));
      // allocation的大小是amountToAllocate, 但在分配它时可能还有预留的空间(initialSlabSize)
    void *initialSlab = (char*)allocation + amountToAllocate;
    task->Private.initializeWithSlab(basePriority, initialSlab,
                                     initialSlabSize);
  } else { // 没有预留的空间
    task->Private.initialize(basePriority);
  }

  // Perform additional linking between parent and child task.
    // 在父任务和子任务之间执行额外的链接。
  if (parent) {
    // If the parent was already cancelled, we carry this flag forward to the child.
      // 如果父任务已经取消, 将标记传递到子任务中
    //
    // In a task group we would not have allowed the `add` to create a child anymore,
    // however better safe than sorry and `async let` are not expressed as task groups,
    // so they may have been spawned in any case still.
      // 在任务组中，我们不再允许“add”创建子任务，但是安全总比后悔好，并且“async let”并未表示为任务组，因此无论如何它们可能仍然会被生成。
    if ((group && group->isCancelled()) || swift_task_isCancelled(parent))
      swift_task_cancel(task);

    // Inside a task group, we may have to perform some defensive copying,
    // check if doing so is necessary, and initialize storage using partial
    // defensive copies if necessary.
    if (group) {
      assert(parent && "a task created in a group must be a child task");
    }

    // Initialize task locals with a link to the parent task.
      // 使用指向父任务的链接初始化任务本地变量。
    //
    // Inside a task group, we may have to perform some defensive copying,
    // and initialize storage using partial defensive copies if necessary.
      // 在任务组内部，我们可能必须执行一些防御性复制，并在必要时使用部分防御性复制初始化存储。
    //
    // If we were going to copy ALL values anyway, we don't need to
    // perform this defensive partial copying. In practice, we currently
    // do not have child tasks which force copying, but we could.
      // 如果我们无论如何都要复制所有值，则无需执行这种防御性部分复制。实际上，我们目前没有强制复制的子任务，但我们可以。
    assert(!taskCreateFlags.copyTaskLocals() &&
           "Currently we don't have child tasks which force copying task "
           "locals; unexpected attempt to combine the two!");
      // 复制堆栈(parent到task)
    task->_private().Local.initializeLinkParent(task, parent);
  }

  // Configure the initial context.
  //
  // FIXME: if we store a null pointer here using the standard ABI for
  // signed null pointers, then we'll have to authenticate context pointers
  // as if they might be null, even though the only time they ever might
  // be is the final hop.  Store a signed null instead.
    // FIXME：如果我们使用有符号空指针的标准 ABI 在此处存储空指针，则我们必须对上下文指针进行验证，
    // 就好像它们可能为空一样，即使它们唯一可能为空的时间是最后一跳。请存储有符号空值。
  initialContext->Parent = nullptr;

  // FIXME: add discarding flag
  // FIXME: add task executor
  concurrency::trace::task_create(
      task, parent, group, asyncLet,
      static_cast<uint8_t>(task->Flags.getPriority()),
      task->Flags.task_isChildTask(), task->Flags.task_isFuture(),
      task->Flags.task_isGroupChildTask(), task->Flags.task_isAsyncLetTask());

  // Attach to the group, if needed.
  if (group) {
    swift_taskGroup_attachChild(group, task);
#if SWIFT_CONCURRENCY_TASK_TO_THREAD_MODEL
    // We need to take a retain here to keep the child task for the task group
    // alive. In the non-task-to-thread model, we'd always take this retain
    // below since we'd enqueue the child task. But since we're not going to be
    // enqueueing the child task in this model, we need to take this +1 to
    // balance out the release that exists after the task group child task
    // creation
    swift_retain(task);
#endif
  }

  // If we're supposed to copy task locals, do so now.
  if (taskCreateFlags.copyTaskLocals()) {
      // 复制cur-task的堆栈到task
    swift_task_localsCopyTo(task);
  }

  // Push the async let task status record.
  if (asyncLet) {
      // 这里初始化asyncLet的空间, 构造record, 加到当前线程的task->status中
    asyncLet_addImpl(task, asyncLet, !hasAsyncLetResultBuffer);
  }

  // Task executor preference
  // If the task does not have a specific executor set already via create
  // options, and there is a task executor preference set in the parent, we
  // inherit it by deep-copying the preference record. if
  // (shouldPushTaskExecutorPreferenceRecord || taskExecutor.isDefined()) {
    // 任务执行器偏好 如果任务尚未通过创建选项设置特定的执行器，并且父级中设置了任务执行器偏好，则我们通过深度复制偏好记录来继承它。
  if (jobFlags.task_hasInitialTaskExecutorPreference()) {
    // Implementation note: we must do this AFTER `swift_taskGroup_attachChild`
    // because the group takes a fast-path when attaching the child record.
    assert(jobFlags.task_hasInitialTaskExecutorPreference());
      // 在当前task上创建record
    task->pushInitialTaskExecutorPreference(
        taskExecutor, /*owned=*/taskExecutorIsOwned);
  }

  // If we're supposed to enqueue the task, do so now.
  if (taskCreateFlags.enqueueJob()) {
#if SWIFT_CONCURRENCY_TASK_TO_THREAD_MODEL
    assert(false && "Should not be enqueuing tasks in task-to-thread model");
#endif
    swift_retain(task);
    task->flagAsAndEnqueueOnExecutor(
        serialExecutor);
  }

  return {task, initialContext};
}
```


### 汇编过程

```lua
// x22: 0x0000000151e05420(AsyncContext*)
    // _context有32字节的空间(汇编跟踪调试得出), 不确定是什么类型的AsyncContext
    //  <0~7bit>: Parent = nullptr
    //  <8~15bit>: completeTaskWithClosure
    //  <16~23bit>: 还未填充
    //  <24~32bit>: 还未填充
// x19: 0x0000000151e05320(AsyncTask*),
static void future_adapter(SWIFT_ASYNC_CONTEXT AsyncContext *_context) {
    // FutureAsyncContextPrefix* ctx_prefix = _context - sizeof(FutureAsyncContextPrefix)(32)
    // ctx_prefix->asyncEntryPoint(
    //  ctx_prefix->indirectResult
    //  _context
    //  ctx_prefix->closureContext
    // )
    //asyncEntryPoint是函数入口点
}


/*
x0 = 0x00000001536053f8
x1 = 0x0000000153605408
x2 = 0x0000000100003a44
    swift`partial apply forwarder for reabstraction thunk helper from @escaping @convention(thin) @async () -> () to @escaping @callee_guaranteed @async () -> (@out (), @error @owned Swift.Error) at <compiler-generated>
x20 = 0x0000600001d37980
x22 = 0x0000000153605420

x0: FutureAsyncContextPrefix->indirectResult, 结果存储的地址
x1: ctx - 0x18 ==> &(FutureAsyncContextPrefix->asyncEntryPoint)
x2: FutureAsyncContextPrefix->asyncEntryPoint, 即当前函数的地址
x20: FutureAsyncContextPrefix->closureContext, asyncEntryPoint的上下文     简称: enter-ctx(指针)
x22: AsyncContext*,                                                      简称: ctx(指针, 表示上下文对象的地址)
PS: x1和x2不一样, x1是ctxpre偏移8字节的地址, 然后该地址指向的空间里存储的是x2的值
*/


swift`partial apply for thunk for @escaping @convention(thin) @async () -> ():
->  0x100003a44 <+0>:   orr    x29, x29, #0x1000000000000000 // 拆分函数的第1条指令都是这个,后续会还原
0x100003a48 <+4>:   sub    sp, sp, #0x40
0x100003a4c <+8>:   stp    x29, x30, [sp, #0x30]
0x100003a50 <+12>:  str    x22, [sp, #0x28]         // 不同于一般的函数, 拆分函数的汇编在真正建立stack前会先将x22(上下文)保存在堆栈中, 并且是固定的sp - 28
0x100003a54 <+16>:  add    x29, sp, #0x30           // 至此建立stack
0x100003a58 <+20>:  stur   x0, [x29, #-0x10]        // *(x29 - 0x10) = result-0
0x100003a5c <+24>:  mov    x8, x22                  // x8 = ctx
0x100003a60 <+28>:  str    x8, [sp]                 // *sp = ctx
0x100003a64 <+32>:  mov    x22, x8
0x100003a68 <+36>:  str    x22, [x8, #0x10]         // *(x8 + 0x10) = ctx,          (*ctx)<16~23bit> = ctx
0x100003a6c <+40>:  ldr    x8, [x20, #0x10]         // x8 = *(enter-ctx + 0x10),    0x0000000100008000(async_MainTu), 一个全局对象
0x100003a70 <+44>:  str    x8, [sp, #0x18]          // *(sp + 0x18) = async_MainTu
0x100003a74 <+48>:  adrp   x8, 5
0x100003a78 <+52>:  str    x8, [sp, #0x8]           // *(sp + 8) = 0x0000000100008000, 这次不一样, 直接读取全局对象
0x100003a7c <+56>:  adrp   x8, 5
0x100003a80 <+60>:  add    x8, x8, #0x8              ; async function pointer to reabstraction thunk helper from @escaping @convention(thin) @async () -> () to @escaping @callee_guaranteed @async () -> (@out (), @error @owned Swift.Error)
                                                    // x8 = async_MainTu + 8

0x100003a84 <+64>:  str    x8, [sp, #0x10]          // *(sp + 0x10) = async_MainTu + 8
0x100003a88 <+68>:  ldr    w8, [x8, #0x4]           // w8 = 0x20,                   通过汇编调试, 大小是32
0x100003a8c <+72>:  mov    x0, x8                   // x0 = 32
0x100003a90 <+76>:  bl     0x100003efc               ; symbol stub for: swift_task_alloc
                                                    // x0 = ctx-1
0x100003a94 <+80>:  ldr    x10, [sp]                // x10= *sp = ctx
0x100003a98 <+84>:  ldr    x9, [sp, #0x8]           // x9 = *(sp + 0x8) = async_MainTu
0x100003a9c <+88>:  ldr    x8, [sp, #0x10]          // x8 = *(sp + 0x10)= async_MainTu + 8
0x100003aa0 <+92>:  ldr    x1, [sp, #0x18]          // x1 = *(sp + 0x18)= async_MainTu
0x100003aa4 <+96>:  mov    x22, x0                  // x22 = ctx-1
0x100003aa8 <+100>: ldur   x0, [x29, #-0x10]        // x0 = *(x29 - 0x10) = result-0
0x100003aac <+104>: mov    x11, x22                 // x11 = ctx-1
0x100003ab0 <+108>: str    x11, [x10, #0x18]        // *(x10 + 0x18) = x11          (*ctx)<24~31bit> = ctx-1, 至此ctx的32字节全部填充完毕
0x100003ab4 <+112>: ldr    x10, [x10, #0x10]        // x10 = *(x10 + 0x10)          x10 = ctx
0x100003ab8 <+116>: str    x10, [x22]               // *x22 = x10                   ctx-1<0~7bit> = ctx, ctx-1.Parent = ctx
0x100003abc <+120>: adrp   x10, 0
0x100003ac0 <+124>: add    x10, x10, #0xae0          ; (1) await resume partial function for partial apply forwarder for reabstraction thunk helper from @escaping @convention(thin) @async () -> () to @escaping @callee_guaranteed @async () -> (@out (), @error @owned Swift.Error) at <compiler-generated>
                                                    // 这个地址对应的是<+156>这条指令, 当<+152>完毕后, 应该回到<+156>继续执行
0x100003ac4 <+128>: str    x10, [x22, #0x8]
                                                    // *(x22 + 8) = x10             ctx-1<8~16bit> = resume-func-1, ctx-1.completeTaskWithClosure = resume-func
0x100003ac8 <+132>: ldrsw  x9, [x9, #0x8]           // x9 = *(x9 + 8)               x9 = *(async_MainTu + 8) = 0xffffffffffffb938
0x100003acc <+136>: add    x2, x8, x9               // x2 = x8 + x9                 x2 = 0x0000000100008008 + 0xffffffffffffb938 = 0x0000000100003940
0x100003ad0 <+140>: ldp    x29, x30, [sp, #0x30]
0x100003ad4 <+144>: and    x29, x29, #0xefffffffffffffff
0x100003ad8 <+148>: add    sp, sp, #0x40            // 还原stack, 由于当前函数未返回就直接销毁了stack, 所以在xcode上表现的行为: 当前函数的栈桢结束, 并且变为x2的栈桢
0x100003adc <+152>: br     x2                       // 跳转到下一个拆分函数





// x22 = ctx-1
// x1 = async_MainTu
swift`thunk for @escaping @convention(thin) @async () -> ():
->  0x100003940 <+0>:   orr    x29, x29, #0x1000000000000000
0x100003944 <+4>:   sub    sp, sp, #0x30
0x100003948 <+8>:   stp    x29, x30, [sp, #0x20]
0x10000394c <+12>:  str    x22, [sp, #0x18]         // *(sp + 0x18) = ctx-1
0x100003950 <+16>:  add    x29, sp, #0x20
0x100003954 <+20>:  mov    x8, x22                  // x8 = ctx-1
0x100003958 <+24>:  str    x8, [sp, #0x8]           // *(sp + 8) = ctx-1
0x10000395c <+28>:  mov    x22, x8
0x100003960 <+32>:  str    x22, [x8, #0x10]         // *(x8 + 0x10) = x22           ctx-1<16~23bit> = ctx-1
0x100003964 <+36>:  ldrsw  x9, [x1]                 // x9 = *async_mainTu           x9 = 0xffffffffffffb6fc(汇编调试出来)
0x100003968 <+40>:  mov    x8, x1                   // x8 = async_mainTu
0x10000396c <+44>:  add    x8, x8, x9               // x8 = x8 + x9                 x8 = 0x00000001000036fc(async_Main)
0x100003970 <+48>:  str    x8, [sp, #0x10]          // *(sp + 0x10) = async_Main
0x100003974 <+52>:  ldr    w8, [x1, #0x4]           // w8 = *(x1 + 4)               x8 = 0x70
0x100003978 <+56>:  mov    x0, x8                   // x0 = 0x70
0x10000397c <+60>:  bl     0x100003efc               ; symbol stub for: swift_task_alloc
                                                    // x0 = ctx-2
0x100003980 <+64>:  ldr    x8, [sp, #0x8]           // x8 = *(sp + 8) = ctx-1
0x100003984 <+68>:  mov    x22, x0                  // x22 = ctx-2
0x100003988 <+72>:  ldr    x0, [sp, #0x10]          // *(sp + 0x10) = async_Main
0x10000398c <+76>:  mov    x9, x22                  // x9 = ctx-2
0x100003990 <+80>:  str    x9, [x8, #0x18]          // *(x8 + 0x18) = ctx-2         ctx-1<24~31bit> = ctx-2
0x100003994 <+84>:  ldr    x8, [x8, #0x10]          // x8 = *(x8 + 0x10)            x8 = ctx-1<16~23bit> = ctx-1
0x100003998 <+88>:  str    x8, [x22]                // *x22 = ctx-1                 ctx-2<0~7bit> = ctx-1
0x10000399c <+92>:  adrp   x8, 0
0x1000039a0 <+96>:  add    x8, x8, #0x9b8            ; (1) await resume partial function for reabstraction thunk helper from @escaping @convention(thin) @async () -> () to @escaping @callee_guaranteed @async () -> (@out (), @error @owned Swift.Error) at <compiler-generated>
0x1000039a4 <+100>: str    x8, [x22, #0x8]
                                                    // *(x22 + 8) = x8              ctx-2<8~15bit> = resume-func-2
0x1000039a8 <+104>: ldp    x29, x30, [sp, #0x20]
0x1000039ac <+108>: and    x29, x29, #0xefffffffffffffff
0x1000039b0 <+112>: add    sp, sp, #0x30
0x1000039b4 <+116>: br     x0                       // x0 = async_Main, 所以这里跳转到该函数, 并且xcode中的调用栈直接销毁当前函数, 进入到async_Main



// x22: ctx-2
// PS: 该函数才是用户书写的main函数, 前面的都是在拆分main函数, 并且当前函数也只是整个main函数的部分代码, 后面因为有调用async函数, 所以在当前函数中还要继续拆分
swift`async_Main:
->  0x1000036fc <+0>:   orr    x29, x29, #0x1000000000000000
0x100003700 <+4>:   sub    sp, sp, #0x40
0x100003704 <+8>:   stp    x29, x30, [sp, #0x30]
0x100003708 <+12>:  str    x22, [sp, #0x28]
0x10000370c <+16>:  add    x29, sp, #0x30
0x100003710 <+20>:  str    x22, [sp, #0x18]         // *(sp + 0x18) = ctx-2
0x100003714 <+24>:  mov    x8, x22
0x100003718 <+28>:  str    x8, [x22, #0x40]         // *(x22 + 0x40) = ctx-2        ctx-2<0x40(64)~0x47(71)bit> = ctx-2
0x10000371c <+32>:  bl     0x100003f2c               ; symbol stub for: swift_task_getMainExecutor SerialExecutorRef{Identity<0x00000001000d8dc0,_dispatch_main_q>, Implementation<0x000000027c65b0d8, 实现>}
0x100003720 <+36>:  str    x0, [x22, #0x48]         // x0 = gcd_main_q              ctx-2<0x48(72) ~ 0x4f(79)bit> = gcd_main_q
0x100003724 <+40>:  str    x1, [x22, #0x50]         // x1 = MainActor的实现          ctx-2<0x50(80) ~ 0x57(87)bit> = MainActor实现
0x100003728 <+44>:  adrp   x9, 5                    // x9 = 0x100008000(全局区地址), 从这里也看出了 async_MainTu是主线程所在的全局隔离区
0x10000372c <+48>:  mov    w8, #0x14                 ; =20
0x100003730 <+52>:  str    x8, [x9, #0x38]          // *(x9 + 0x38) = x8 = 20       A = 20
0x100003734 <+56>:  adrp   x9, 5
0x100003738 <+60>:  str    x9, [sp, #0x8]           // *(sp + 8) = async_MainTu
0x10000373c <+64>:  adrp   x0, 5
0x100003740 <+68>:  add    x0, x0, #0x40             ; swift.B : Swift.Int          x0 = &B
0x100003744 <+72>:  mov    w8, #0x1e                 ; =30
0x100003748 <+76>:  str    x8, [x9, #0x40]          // *(x9 + 0x40) = 30            B = 30
0x10000374c <+80>:  add    x1, x22, #0x10           // x1 = x22 + 0x10              x1 = ctx-2 + 0x10
0x100003750 <+84>:  str    x1, [sp, #0x10]          // *(sp + 0x10) = ctx-2 + 0x10
0x100003754 <+88>:  mov    w8, #0x20                 ; =32
0x100003758 <+92>:  mov    x2, x8                   // x2 = x8
0x10000375c <+96>:  mov    x3, #0x0                  ; =0
0x100003760 <+100>: bl     0x100003ecc               ; symbol stub for: swift_beginAccess
                                                    // 需要的4个参数:
                                                    //  1. x0 = &B
                                                    //  2. x1 = ctx-2 + 0x10(Access*, 由函数原型推断出来)
                                                    //  3. x2 = 32(动作读取)
                                                    //  4. x3 = 0, 函数的第4个参数其实是PC(指令地址, 事实上在函数内部因为传递了nullptr会被初始化为return的地址)
                                                    // 结合以前的swift_beginAccess, 在涉及到异步函数时, 处理的逻辑是一样的, 但参数传递机制不同
0x100003764 <+104>: ldr    x8, [sp, #0x8]           // x8 = *(sp + 8) = async_MainTu
0x100003768 <+108>: ldr    x0, [sp, #0x10]          // x0 = *(sp + 0x10) = ctx-2 + 0x10, 准备传递给 swift_endAccess
0x10000376c <+112>: ldr    x8, [x8, #0x40]          // x8 = *(x8 + 0x40)            x8 = B(全局对象) = 30
0x100003770 <+116>: stur   x8, [x29, #-0x10]        // *(x29 - 0x10) = x8 = 30
0x100003774 <+120>: bl     0x100003ee4               ; symbol stub for: swift_endAccess
                                                    // 销毁TLS中的Access
0x100003778 <+124>: adrp   x8, 5
0x10000377c <+128>: add    x8, x8, #0x18             ; async function pointer to swift.f(a: Swift.Int) async throws -> Swift.Int
                                                    // x8 = 0x100008018 = f(a: Int) 函数信息, 由于该函数内部也调用了await, 所以它本身也会被拆分成多个函数, 这里的信息就记录了该函数要开辟多大的数据空间, 由编译器创建
0x100003780 <+132>: ldr    w8, [x8, #0x4]           // w8 = 64(汇编调试), 要获取64字节大小的内存
0x100003784 <+136>: mov    x0, x8                   // x0 = 64
0x100003788 <+140>: bl     0x100003efc               ; symbol stub for: swift_task_alloc
                                                    // x0 = ctx-3

0x10000378c <+144>: ldr    x8, [sp, #0x18]          // x8 = *(sp + 0x18) = ctx-2
0x100003790 <+148>: mov    x22, x0                  // x22 = ctx-3
0x100003794 <+152>: ldur   x0, [x29, #-0x10]        // x0 = *(x29 - 0x10) = 30
0x100003798 <+156>: mov    x9, x22                  // x9 = ctx-3
0x10000379c <+160>: str    x9, [x8, #0x58]          // *(x8 + 0x58) = ctx-3         (*ctx-2)<0x58(88) ~ 0x5f(95)bit> = ctx-3
0x1000037a0 <+164>: ldr    x8, [x8, #0x40]          // x8 = *(x8 + 0x40)= ctx-2
0x1000037a4 <+168>: str    x8, [x22]                // *x22 = ctx-2                 (*ctx-3)<0~7bit> = ctx-2
0x1000037a8 <+172>: adrp   x8, 0
0x1000037ac <+176>: add    x8, x8, #0x7c4            ; async_MainTQ0_ at <compiler-generated>
                                                    // x8 = 0x1000087c4<+196>(async_MainTQ0_)
0x1000037b0 <+180>: str    x8, [x22, #0x8]          // *(x22 + 8) = x8              (*ctx-3)<8~15bit> = async_MainTQ0_
0x1000037b4 <+184>: ldp    x29, x30, [sp, #0x30]
0x1000037b8 <+188>: and    x29, x29, #0xefffffffffffffff
0x1000037bc <+192>: add    sp, sp, #0x40
0x1000037c0 <+196>: b      0x100003b40               ; swift.f(a: Swift.Int) async throws -> Swift.Int at main.swift:14


// x22: ctx-3
// x0: 参数, 前面传递过来的是30
// PS: 此刻并未真正进入到用户书写的 func f(a: Int) async throws -> Int 中, 这里要处理参数
swift`f(a:):
->  0x100003b40 <+0>:  str    x0, [x22, #0x28]      // *(x22 + 0x28) = 30           (*ctx-3)<0x28(40) ~ 0x2f(47)bit> = 30
0x100003b44 <+4>:  mov    x8, x22                   // x8 = ctx-3
0x100003b48 <+8>:  str    x8, [x22, #0x10]          // *(x22 + 0x10) = ctx-3        (*ctx-3)<16~23bit> = ctx-3
0x100003b4c <+12>: add    x8, x22, #0x18            // x8 = x22 + 0x18
0x100003b50 <+16>: str    xzr, [x22, #0x18]         // *(x22 + 0x18) = 0, *x8 = 0
0x100003b54 <+20>: str    xzr, [x22, #0x20]         // *(x22 + 0x20) = 0            (*ctx-3)<0x20(32)~0x27(39)bit> = 0, 用来存储结果的
0x100003b58 <+24>: str    x0, [x22, #0x18]          // *(x22 + 0x18) = 30           (*ctx-3)<0x18(24)~0x1f(31)bit> = 30, 参数
0x100003b5c <+28>: ldr    x22, [x22, #0x10]         // x22 = *(x22 + 0x10) = ctx-3
0x100003b60 <+32>: adrp   x0, 0
0x100003b64 <+36>: add    x0, x0, #0xb74            ; (1) suspend resume partial function for swift.f(a: Swift.Int) async throws -> Swift.Int at main.swift:14
                                                    // x0 = 0x100003b74<+52>
0x100003b68 <+40>: mov    x2, #0x0                  ; =0
0x100003b6c <+44>: mov    x1, x2                    // x1 = 0
0x100003b70 <+48>: b      0x100003f38               ; symbol stub for: swift_task_switch
                                                    // swift_task_switch的签名
                                                            // void swift_task_switch(AsyncContext *resumeContext,
                                                            //                        TaskContinuationFunction *resumeFunction,
                                                            //                        SerialExecutorRef newExecutor);
                                                    // 参数0: x22(ctx-3)
                                                    // 参数1: x0(0x100003b74), 函数执行地址
                                                    // 参数2: x1 = 0
                                                    // 后续会执行到 swift_task_switchImpl, 参数不变



// 由swift_task_switch内部调度而来, 此刻已经在子线程中(gcd的并发队列)
// x22: ctx-3
swift`f(a:):
0x100003b74 <+0>:   orr    x29, x29, #0x1000000000000000
0x100003b78 <+4>:   sub    sp, sp, #0x30
0x100003b7c <+8>:   stp    x29, x30, [sp, #0x20]
0x100003b80 <+12>:  str    x22, [sp, #0x18]         // *(sp + 0x18) = ctx-3
->  0x100003b84 <+16>:  add    x29, sp, #0x20
0x100003b88 <+20>:  mov    x9, x22                  // x9 = ctx-3
0x100003b8c <+24>:  str    x9, [sp, #0x8]           // *(sp + 8) = ctx-3
0x100003b90 <+28>:  ldr    x8, [x9, #0x28]          // x8 = *(x9 + 0x28) = 30,      因为(*ctx)<0x28(40)~0x2f(47)bit> = 30
0x100003b94 <+32>:  mov    x22, x9
0x100003b98 <+36>:  str    x22, [x9, #0x10]         // *(x9 + 0x10) = ctx-3, 其实原来就是ctx-3
0x100003b9c <+40>:  adds   x8, x8, #0x14            // x8 += 20
0x100003ba0 <+44>:  str    x8, [sp, #0x10]          // *(sp + 0x10) = 50(结果) 即源码中的 number = a + 20
0x100003ba4 <+48>:  cset   w8, vs
0x100003ba8 <+52>:  tbnz   w8, #0x0, 0x100003c08     ; <+148> [inlined] Swift runtime failure: arithmetic overflow at <compiler-generated>
                                                    // 检查是否溢出了

0x100003bac <+56>:  b      0x100003bb0               ; <+60> at main.swift, 未溢出
0x100003bb0 <+60>:  ldr    x8, [sp, #0x10]          // x8 = *(sp + 0x10) = 50(结果)
0x100003bb4 <+64>:  ldr    x9, [sp, #0x8]           // x9 = *(sp + 8) = ctx-3
0x100003bb8 <+68>:  str    x8, [x9, #0x20]          // *(x9 + 0x20) = 50, (*ctx-3)<0x20(32)~0x27(39)bit> = 50
0x100003bbc <+72>:  adrp   x8, 5
0x100003bc0 <+76>:  add    x8, x8, #0x20             ; async function pointer to swift.f2(a: Swift.Int) async -> Swift.Int
                                                    // x8 = 0x100003020, 获取f2函数的信息
0x100003bc4 <+80>:  ldr    w8, [x8, #0x4]           // 获取f2函数需要的大小(参数和局部对象)
0x100003bc8 <+84>:  mov    x0, x8                   // 48
0x100003bcc <+88>:  bl     0x100003efc               ; symbol stub for: swift_task_alloc
                                                    // x0 = ctx-4
0x100003bd0 <+92>:  ldr    x8, [sp, #0x8]           // x8 = *(sp + 8) = ctx-3
0x100003bd4 <+96>:  mov    x22, x0                  // x22 = ctx-4
0x100003bd8 <+100>: ldr    x0, [sp, #0x10]          // x0 = *(sp + 0x10) = 50(结果)
0x100003bdc <+104>: mov    x9, x22                  // x9 = ctx-4
0x100003be0 <+108>: str    x9, [x8, #0x30]          // *(x8 + 0x30) = ctx-4,        (*ctx-3)<0x30(48)~0x37(55)bit> = ctx-4, <0x38(56)~0x3f(63)bit>存储结果
0x100003be4 <+112>: ldr    x8, [x8, #0x10]          // x8 = ctx-3
0x100003be8 <+116>: str    x8, [x22]                // *x22 = x8 = ctx-3            (*ctx-4)<0~7bit> = ctx-3
0x100003bec <+120>: adrp   x8, 0
0x100003bf0 <+124>: add    x8, x8, #0xc0c            ; (2) await resume partial function for swift.f(a: Swift.Int) async throws -> Swift.Int at main.swift:16
                                                    // x8 = 0x100003c0c<+152>, 当后面的函数返回时应该要调用的函数地址
0x100003bf4 <+128>: str    x8, [x22, #0x8]          // *(x22 + 8) = x8              (*ctx-4)<8~15bit> = <0x100003c0c +152>
0x100003bf8 <+132>: ldp    x29, x30, [sp, #0x20]
0x100003bfc <+136>: and    x29, x29, #0xefffffffffffffff
0x100003c00 <+140>: add    sp, sp, #0x30
0x100003c04 <+144>: b      0x100003cdc               ; swift.f2(a: Swift.Int) async -> Swift.Int at main.swift:9
0x100003c08 <+148>: brk    #0x1




// x22: ctx-4
// x0: 参数(50)
swift`f2(a:):
->  0x100003cdc <+0>:   orr    x29, x29, #0x1000000000000000
0x100003ce0 <+4>:   sub    sp, sp, #0x30
0x100003ce4 <+8>:   stp    x29, x30, [sp, #0x20]
0x100003ce8 <+12>:  str    x22, [sp, #0x18]         // *(sp + 0x18) = ctx-4
0x100003cec <+16>:  add    x29, sp, #0x20
0x100003cf0 <+20>:  str    x22, [sp, #0x8]          // *(sp + 8) = ctx-4
0x100003cf4 <+24>:  str    x0, [sp, #0x10]          // *(sp + 0x10) = 50
0x100003cf8 <+28>:  mov    x8, x22
0x100003cfc <+32>:  str    x8, [x22, #0x10]         // *(x22 + 0x10) = ctx-4        (*ctx-4)<0x10(16)~0x17(23)bit> = ctx-4
0x100003d00 <+36>:  add    x8, x22, #0x18           // x8 = x22 + 0x18
0x100003d04 <+40>:  str    xzr, [x22, #0x18]
0x100003d08 <+44>:  str    xzr, [x22, #0x20]
0x100003d0c <+48>:  str    x0, [x22, #0x18]         // *(x22 + 0x18) = 50           (*ctx-4)<0x18(24) ~ 0x1f(31)bit> = 50, <0x20(32) ~ 0x27(39)bit>用来存储结果
0x100003d10 <+52>:  adrp   x8, 5
0x100003d14 <+56>:  add    x8, x8, #0x28             ; async function pointer to swift.f3(a: Swift.Int) async -> Swift.Int
0x100003d18 <+60>:  ldr    w8, [x8, #0x4]
0x100003d1c <+64>:  mov    x0, x8                   // 获取f3函数信息(16字节)
0x100003d20 <+68>:  bl     0x100003efc               ; symbol stub for: swift_task_alloc
0x100003d24 <+72>:  ldr    x8, [sp, #0x8]           // x8 = *(sp + 8) = ctx-4
0x100003d28 <+76>:  mov    x22, x0                  // x22 = ctx-5
0x100003d2c <+80>:  ldr    x0, [sp, #0x10]          // x0 = *(sp + 0x10) = 50
0x100003d30 <+84>:  mov    x9, x22                  // x9 = ctx-5
0x100003d34 <+88>:  str    x9, [x8, #0x28]          // *(x8 + 0x28) = ctx-5         (*ctx-4)<0x28(40) ~ 0x2f(47)bit> = ctx-5
0x100003d38 <+92>:  ldr    x8, [x8, #0x10]          // x8 = ctx-4
0x100003d3c <+96>:  str    x8, [x22]                // *x22 = ctx-4                 (*ctx-5)<0~7bit> = ctx-4
0x100003d40 <+100>: adrp   x8, 0
0x100003d44 <+104>: add    x8, x8, #0xd5c            ; (1) await resume partial function for swift.f2(a: Swift.Int) async -> Swift.Int at main.swift:10
                                                    // x8 = 0x100003d5c<+124>
0x100003d48 <+108>: str    x8, [x22, #0x8]          // *(x22 + 8) = x8              (*ctx-5)<8~15bit> = x8
0x100003d4c <+112>: ldp    x29, x30, [sp, #0x20]
0x100003d50 <+116>: and    x29, x29, #0xefffffffffffffff
0x100003d54 <+120>: add    sp, sp, #0x30
0x100003d58 <+124>: b      0x100003cb0               ; swift.f3(a: Swift.Int) async -> Swift.Int at main.swift:5



// x22: ctx-5
swift`f3(a:):
->  0x100003cb0 <+0>:  sub    sp, sp, #0x10         // 开辟stack, 因为f3函数虽然是异步函数, 但它的内部没有任何await的调用, 所以编译器在编译它时就是一个普通函数(不会拆分)
0x100003cb4 <+4>:  str    x22, [sp, #0x8]           // *(sp + 8) = ctx-5
0x100003cb8 <+8>:  mov    x8, sp                    // x8 = sp
0x100003cbc <+12>: str    xzr, [sp]                 // *sp = 0
0x100003cc0 <+16>: str    x0, [sp]                  // *sp = 50(参数)
0x100003cc4 <+20>: mov    x9, x8                    // x9 = x8 = sp
0x100003cc8 <+24>: ldr    x8, [sp, #0x8]            // x8 = *(sp + 8) = ctx-5
0x100003ccc <+28>: ldr    x1, [x8, #0x8]            // x1 = (*ctx-5)<8~15bit> =  0x100003d5c, 继当前f3函数执行完毕后, 要返回去执行地址
0x100003cd0 <+32>: ldr    x22, [sp, #0x8]           // x22 = *(sp + 8) = ctx-5
0x100003cd4 <+36>: add    sp, sp, #0x10
0x100003cd8 <+40>: br     x1                        // 跳转到 0x100003d5c



// x22: ctx-5
// x0: 50
// ps: 该函数由f3这个异步函数返回,
swift`f2(a:):
->  0x100003d5c <+0>:   orr    x29, x29, #0x1000000000000000
0x100003d60 <+4>:   sub    sp, sp, #0x30
0x100003d64 <+8>:   stp    x29, x30, [sp, #0x20]
0x100003d68 <+12>:  str    x22, [sp, #0x18]         // *(sp + 0x18) = ctx-5
0x100003d6c <+16>:  add    x29, sp, #0x20
0x100003d70 <+20>:  str    x0, [sp, #0x10]          // *(sp + 0x10) = x0 = 50
0x100003d74 <+24>:  ldr    x9, [x22]                // x9 = *x22 = ctx-4, 根据前面的规则, swift_task_alloc后的空间中, 前8字节存储的是父级上下文, 再8字节存储的是要返回到父级的地址, 再8字节存储的是自己, 再后面是携带的信息
0x100003d78 <+28>:  str    x9, [sp, #0x8]           // *(sp + 8) = ctx-4, 在前面的过程中, 拆分的函数中 *(sp + 8) 一般存储的是上下文(自己), 在往回一层一层返回时, 它存储的是父级上下文
0x100003d7c <+32>:  mov    x8, x29                  // x8 = x29, x29是arm64中的fp寄存器, 用来存储当前函数栈桢的底部, 但要注意x29在一进入函数时(拆分函数), 先置位了63bit位(在某些平台下<+0>的操作是没有效果的)
0x100003d80 <+36>:  sub    x8, x8, #0x8             // x8 = x8 - 8
0x100003d84 <+40>:  str    x9, [x8]                 // *x8 = ctx-4, *(x29 - 8) = ctx-4
0x100003d88 <+44>:  ldr    x0, [x9, #0x28]          // x0 = *(x9 + 0x28) = (*ctx-4)<0x28(40) ~ 0x2f(47)bit> = ctx-5
0x100003d8c <+48>:  ldr    x8, [x22]                // x8 = *x22 = (*ctx-5)<0~7bit> = ctx-4
0x100003d90 <+52>:  mov    x10, x29                 // x10 = x29
0x100003d94 <+56>:  sub    x10, x10, #0x8           // x10 = x10 - 8
0x100003d98 <+60>:  str    x8, [x10]                // *x10 = ctx-4, *(x29 - 8) = ctx-4
0x100003d9c <+64>:  str    x8, [x9, #0x10]          // *(x9 + 0x10) = (*ctx-4)<0x10(16) ~ 0x17(23)bit> = ctx-4
0x100003da0 <+68>:  bl     0x100003f20               ; symbol stub for: swift_task_dealloc
                                                    // 注意这里传递的参数是x0(ctx-5), 相当于销毁ctx5, 因为ctx-5用于f3函数, 而f3函数已经调用完毕
0x100003da4 <+72>:  ldr    x8, [sp, #0x8]           // x8 = *(sp + 8) = ctx-4
0x100003da8 <+76>:  ldr    x0, [sp, #0x10]          // x0 = *(sp + 0x10) = 50
0x100003dac <+80>:  mov    x9, x8                   // x9 = ctx-4
0x100003db0 <+84>:  str    x0, [x9, #0x20]!         // x9 = ctx-4 + 0x20, *x9 = 50, 存储结果到 ctx-4<0x20(32) ~ 0x27(39)bit>
0x100003db4 <+88>:  subs   x10, x9, #0x8            // x10 = x9 - 8 = ctx-4 + 0x20 - 0x8 = ctx-4 + 0x18
0x100003db8 <+92>:  mov    x11, x9                  // x11 = ctx-4 + 0x18
0x100003dbc <+96>:  ldr    x22, [x8, #0x10]         // x22 = *(x8 + 0x10) = (*ctx-4)<0x10(16) ~ 0x1f(23)bit> = ctx-4
0x100003dc0 <+100>: ldr    x1, [x22, #0x8]          // x1 = *(x22 + 8) = ctx-4<8~15bit> = 0x100003c0c, 要返回的地址
0x100003dc4 <+104>: ldp    x29, x30, [sp, #0x20]
0x100003dc8 <+108>: and    x29, x29, #0xefffffffffffffff
0x100003dcc <+112>: add    sp, sp, #0x30
0x100003dd0 <+116>: br     x1




// x22: ctx-4
// x0: 50
swift`f(a:):
->  0x100003c0c <+0>:   orr    x29, x29, #0x1000000000000000
0x100003c10 <+4>:   sub    sp, sp, #0x20
0x100003c14 <+8>:   stp    x29, x30, [sp, #0x10]
0x100003c18 <+12>:  str    x22, [sp, #0x8]          // *(sp + 8) = ctx-4
0x100003c1c <+16>:  add    x29, sp, #0x10
0x100003c20 <+20>:  mov    x8, x0                   // x8 = 50
0x100003c24 <+24>:  ldr    x9, [x22]                // x9 = *x22 = ctx-4<0~7bit> = ctx-3
0x100003c28 <+28>:  str    x9, [sp]                 // *sp = ctx-3
0x100003c2c <+32>:  mov    x10, x29                 // x10 = x29
0x100003c30 <+36>:  sub    x10, x10, #0x8           // x10 -= 8
0x100003c34 <+40>:  str    x9, [x10]                // *x10 = ctx-3,  相当于 *(x29 - 8) = ctx-3
0x100003c38 <+44>:  ldr    x0, [x9, #0x30]          // x0 = *(x9 + 0x30) = ctx-3<0x30(48) ~ 0x37(55)bit> = ctx-4
0x100003c3c <+48>:  ldr    x10, [x22]               // x10 = *x22 = ctx-3
0x100003c40 <+52>:  mov    x11, x29                 // x11 = x29
0x100003c44 <+56>:  sub    x11, x11, #0x8           // x11 -= 8
0x100003c48 <+60>:  str    x10, [x11]               // *x11 = ctx-3, 相当于 *(x29 - 8) = ctx-3
0x100003c4c <+64>:  str    x10, [x9, #0x10]         // *(x9 + 0x10) = ctx-3<0x10(16) ~ 0x1f(23)bit> = ctx-3
0x100003c50 <+68>:  str    x8, [x9, #0x38]          // *(x9 + 0x38) = ctx-3<0x38(56) ~ 0x3f(63)bit> = 50
0x100003c54 <+72>:  bl     0x100003f20               ; symbol stub for: swift_task_dealloc
                                                        // 释放ctx-4(x0)
0x100003c58 <+76>:  ldr    x8, [sp]                 // x8 = *sp = ctx-3
0x100003c5c <+80>:  ldr    x22, [x8, #0x10]         // x22 = *(x8 + 0x10) = ctx-3<0x10(16) ~ 0x17(23)bit> = ctx-3
0x100003c60 <+84>:  adrp   x0, 0
0x100003c64 <+88>:  add    x0, x0, #0xc80            ; (3) suspend resume partial function for swift.f(a: Swift.Int) async throws -> Swift.Int at main.swift:16
                                                    // x0 = 0x100003c80<+116>
0x100003c68 <+92>:  mov    x2, #0x0                  ; =0
0x100003c6c <+96>:  mov    x1, x2
0x100003c70 <+100>: ldp    x29, x30, [sp, #0x10]
0x100003c74 <+104>: and    x29, x29, #0xefffffffffffffff
0x100003c78 <+108>: add    sp, sp, #0x20
0x100003c7c <+112>: b      0x100003f38               ; symbol stub for: swift_task_switch
                                                    // 向该函数传递了
                                                    // 参数0: x22(ctx-3)
                                                    // 参数1: resumeFunction(x0)
                                                    // 参数2: nullptr



// 再次去到调度函数中, 这一次发现某些条件符合, 并不会创建新的线程, 是直接在当前线程中调用了  resumeFunction(0x100003c80)
// x22: ctx-3
swift`f(a:):
->  0x100003c80 <+0>:  mov    x8, x22               // x8 = ctx-3
0x100003c84 <+4>:  ldr    x9, [x8, #0x38]           // x9 = *(x8 + 0x38) = (*ctx-3)<0x38(56) ~ 0x3f(63)bit> = 50
0x100003c88 <+8>:  mov    x22, x8
0x100003c8c <+12>: str    x22, [x8, #0x10]          // (*ctx-3)<0x10(16) ~ 0x1f(23)bit> = ctx-3
0x100003c90 <+16>: str    x9, [x8, #0x20]           // (*ctx-3)<0x20(32) ~ 0x27(39)bit> = 50
0x100003c94 <+20>: add    x9, x8, #0x18             // x9 = ctx-3 + 0x18
0x100003c98 <+24>: ldr    x9, [x8, #0x10]           // x9 = (*ctx-3)<0x10(16) ~ 0x17(23)bit> = ctx-3
0x100003c9c <+28>: ldr    x1, [x9, #0x8]            // x1 = (*ctx-3)<8~15bit> = 要返回的指令地址 async_MainTQ0_(0x1000037c4)
0x100003ca0 <+32>: ldr    x22, [x8, #0x10]          // x22 = (*ctx-3)<16 ~ 23bit> = ctx-3
0x100003ca4 <+36>: ldr    x0, [x8, #0x38]           // x0 = (*ctx-3)<0x38(56) ~ 0x3f(63)bit> = 50
0x100003ca8 <+40>: mov    x20, #0x0                 ; =0
0x100003cac <+44>: br     x1




// x22: ctx-3
swift`async_MainTQ0_:
->  0x1000037c4 <+0>:   orr    x29, x29, #0x1000000000000000
0x1000037c8 <+4>:   sub    sp, sp, #0x30
0x1000037cc <+8>:   stp    x29, x30, [sp, #0x20]
0x1000037d0 <+12>:  str    x22, [sp, #0x18]         // *(sp + 0x18) = ctx-3
0x1000037d4 <+16>:  add    x29, sp, #0x20
0x1000037d8 <+20>:  mov    x9, x0                   // x9 = 50
0x1000037dc <+24>:  ldr    x8, [x22]                // x8 = *x22 = ctx-2
0x1000037e0 <+28>:  mov    x10, x29                 // x10 = x29
0x1000037e4 <+32>:  sub    x10, x10, #0x8           // x10 -= 8
0x1000037e8 <+36>:  str    x8, [x10]                // *x10 = ctx-2, *(x29 - 8) = ctx-2
0x1000037ec <+40>:  ldr    x0, [x8, #0x58]          // x0 = *(x8 + 0x58) = (*ctx-2)<0x58(88) ~ 0x5f(95)bit> = ctx-3
0x1000037f0 <+44>:  ldr    x10, [x22]               // x10 = *x22 = ctx-2
0x1000037f4 <+48>:  mov    x11, x29                 // x11 = x29
0x1000037f8 <+52>:  sub    x11, x11, #0x8           // x11 -= 8
0x1000037fc <+56>:  str    x10, [x11]               // *x11 = ctx-2, *(x29 - 8) = ctx-2
0x100003800 <+60>:  str    x10, [x8, #0x40]!        // x8 = ctx-2 + 0x40,  *x8 = (*ctx-2)<0x40(64) ~ 0x47(71)bit> = ctx-2
0x100003804 <+64>:  subs   x10, x8, #0x30           // x10 = x8 - 0x30 = ctx-2 + 0x10
0x100003808 <+68>:  str    x10, [sp, #0x8]          // *(sp + 0x8) = ctx-2 + 0x10
0x10000380c <+72>:  mov    x10, x8                  // x10 = ctx-2 + 0x40
0x100003810 <+76>:  str    x10, [sp, #0x10]         // *(sp + 0x10) = ctx-2 + 0x40
0x100003814 <+80>:  str    x9, [x8, #0x20]          // *(x8 + 0x20) = (*ctx-2)<0x60(96) ~ 0x67(103)bit> = 50
0x100003818 <+84>:  str    x20, [x8, #0x28]         // *(x8 + 0x28) = (*ctx-2)<0x68(104) ~ 0x70(111)bit> = 0(调试出来)
0x10000381c <+88>:  bl     0x100003f20               ; symbol stub for: swift_task_dealloc
                                                    // 释放ctx-3(x0)

0x100003820 <+92>:  cbnz   x20, 0x100003854          ; <+144> at <compiler-generated> x20 != 0 goto __asm 144
0x100003824 <+96>:  b      0x100003828               ; <+100> at main.swift
0x100003828 <+100>: ldr    x8, [sp, #0x8]           // x8 = *(sp + 8) = ctx-2 + 0x10
0x10000382c <+104>: ldr    x9, [sp, #0x10]          // x9 = *(sp + 0x10) = ctx-2 + 0x40
0x100003830 <+108>: ldr    x22, [x9]                // x22 = *x9 = ctx-2<0x40(64) ~ 0x47(71)bit> = ctx-2
0x100003834 <+112>: ldr    x2, [x8, #0x40]          //  x2 = *(x8 + 0x40) = (*ctx-2)<0x50(80) ~ 0x57(87)bit> = MainActor实现
0x100003838 <+116>: ldr    x1, [x8, #0x38]          //  x1 = *(x8 + 0x38) = (*ctx-2)<0x48(72) ~ 0x4f(79)bit> = gcd_main_q
0x10000383c <+120>: adrp   x0, 0
0x100003840 <+124>: add    x0, x0, #0x880            ; async_MainTY1_ at <compiler-generated>
                                                    // x0 = 0x100003880<+192>
0x100003844 <+128>: ldp    x29, x30, [sp, #0x20]
0x100003848 <+132>: and    x29, x29, #0xefffffffffffffff
0x10000384c <+136>: add    sp, sp, #0x30
0x100003850 <+140>: b      0x100003f38               ; symbol stub for: swift_task_switch
                                                    // 传递的参数
                                                    // 参数0: x22(ctx-2)
                                                    // 参数1: x0(0x100003880), 要调度的函数
                                                    // 参数3: {SerialExecutorRef.Identity(gcd_main_q), SerialExecutorRef.Implementation(MainActor实现)}
                                                    //  由于内部的机制, 将唤醒主线程(主线程此刻已经调起了runloop在睡眠), 在gcd的队列上会唤醒

; __asm_144                                         // 这里相当于要结束当前线程(子线程)
0x100003854 <+144>: ldr    x8, [sp, #0x8]           // x8 = *(sp + 8) = ctx-2 + 0x10
0x100003858 <+148>: ldr    x9, [sp, #0x10]          // x9 = *(sp + 0x10) = ctx-2 + 0x40
0x10000385c <+152>: ldr    x22, [x9]                // x22 = *x9 = (*ctx-2)<0x40(64) ~ 0x47(71)bit> = ctx-2
0x100003860 <+156>: ldr    x2, [x8, #0x40]          // x2 = MainActor实现
0x100003864 <+160>: ldr    x1, [x8, #0x38]          // x1 = gcd_main_q
0x100003868 <+164>: adrp   x0, 0
0x10000386c <+168>: add    x0, x0, #0x8e8            ; async_MainTY2_ at <compiler-generated>
                                                    // x0 = 0x1000038e8
0x100003870 <+172>: ldp    x29, x30, [sp, #0x20]
0x100003874 <+176>: and    x29, x29, #0xefffffffffffffff
0x100003878 <+180>: add    sp, sp, #0x30
0x10000387c <+184>: b      0x100003f38               ; symbol stub for: swift_task_switch
                                                    // 参数0: x22(ctx-2)
                                                    // 参数1: x0(0x1000038e8)
                                                    // 参数3: {SerialExecutorRef.Identity(gcd_main_q), SerialExecutorRef.Implementation(MainActor实现)}
                                                    // 注意和前面一段一样的逻辑, 但是启动函数不同, 并且向 gcd_main_q注册的顺序不同, 所以
                                                    // 主线程会被唤醒, 然后按顺序执行:
                                                    //   0x100003880
                                                    //   0x1000038e8







// 这里相当于源码中调用 A = try! await f(a: B) 后的代码
swift`async_MainTY1_:
->  0x100003880 <+0>:   orr    x29, x29, #0x1000000000000000
0x100003884 <+4>:   sub    sp, sp, #0x30
0x100003888 <+8>:   stp    x29, x30, [sp, #0x20]
0x10000388c <+12>:  str    x22, [sp, #0x18]         // *(sp + 0x18) = ctx-2
0x100003890 <+16>:  add    x29, sp, #0x20
0x100003894 <+20>:  ldr    x8, [x22, #0x60]         // x8 = (*ctx-2)<0x60(96) ~ 0x67(103)bit> = 50(结果)
0x100003898 <+24>:  str    x8, [sp, #0x8]           // *(sp + 8) = 50
0x10000389c <+28>:  mov    x8, x22
0x1000038a0 <+32>:  str    x8, [x22, #0x40]         // (*ctx-2)<0x40(64) ~ 0x47(71)bit> = ctx-2
0x1000038a4 <+36>:  adrp   x8, 5
0x1000038a8 <+40>:  str    x8, [sp]
0x1000038ac <+44>:  adrp   x0, 5
0x1000038b0 <+48>:  add    x0, x0, #0x38             ; swift.A : Swift.Int
                                                    // x0 = &A
0x1000038b4 <+52>:  add    x1, x22, #0x28           // x1 = ctx-2 + 0x28
0x1000038b8 <+56>:  str    x1, [sp, #0x10]          // *(sp + 0x10) = ctx-2 + 0x28
0x1000038bc <+60>:  mov    w8, #0x21                 ; =33
0x1000038c0 <+64>:  mov    x2, x8
0x1000038c4 <+68>:  mov    x3, #0x0                  ; =0
0x1000038c8 <+72>:  bl     0x100003ecc               ; symbol stub for: swift_beginAccess
                                                    // 源码中要访问全局对象A, 所以这里要调用beginAccess
0x1000038cc <+76>:  ldr    x9, [sp]
0x1000038d0 <+80>:  ldr    x8, [sp, #0x8]
0x1000038d4 <+84>:  ldr    x0, [sp, #0x10]
0x1000038d8 <+88>:  str    x8, [x9, #0x38]
0x1000038dc <+92>:  bl     0x100003ee4               ; symbol stub for: swift_endAccess
                                                    // 删除临时资源

0x1000038e0 <+96>:  mov    w0, #0x0                  ; =0
0x1000038e4 <+100>: bl     0x100003eb4               ; symbol stub for: exit
                                                    // 结束程序
```




 



[^ann-concurrency]: 进程和线程, 笔者这里并不过度讨论这些概念.
[^ann-triditional]: 传统线程指的是调度发生在内核中, 会伴随线程上下文切换, 而现代线程模型的调度发生在用户态, 整个调度由运行库处理. 
[^ann-struct-concurrency]: 所谓的结构化并发直接理解为顺序执行的并发代码
</font>

